{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **ğŸ“„ Document type classification baseline code**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n",
    "> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "* ë¡œì»¬ data í´ë”ì—ì„œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21945,
     "status": "ok",
     "timestamp": 1700314517484,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "pUjnEto4gIZm",
    "outputId": "0999f10c-e1ff-428c-995b-481eec8a0b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ê²½ë¡œ: /home/james/doc-classification/computervisioncompetition-cv3/data\n",
      "ë°ì´í„° í´ë” ì¡´ì¬ ì—¬ë¶€: True\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
    "# ë¡œì»¬ data í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "import os\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ data í´ë” ê²½ë¡œ ì„¤ì •\n",
    "project_root = os.path.abspath('..')  # shared í´ë”ì—ì„œ ìƒìœ„ í´ë”ë¡œ ì´ë™\n",
    "data_path = os.path.join(project_root, 'data')\n",
    "\n",
    "print(f\"ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "print(f\"ë°ì´í„° í´ë” ì¡´ì¬ ì—¬ë¶€: {os.path.exists(data_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1700314537985,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "5lFQ-gpjnN_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° í´ë” ë‚´ìš©:\n",
      "  ğŸ“ test/\n",
      "  ğŸ“„ meta.csv\n",
      "  ğŸ“„ sample_submission.csv\n",
      "  ğŸ“ train/\n",
      "  ğŸ“„ train.csv\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° í´ë” ë‚´ìš© í™•ì¸\n",
    "# data í´ë”ì— ìˆëŠ” íŒŒì¼ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "import os\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    print(\"ë°ì´í„° í´ë” ë‚´ìš©:\")\n",
    "    for item in os.listdir(data_path):\n",
    "        item_path = os.path.join(data_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  ğŸ“ {item}/\")\n",
    "        else:\n",
    "            print(f\"  ğŸ“„ {item}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (0.6.12)\n",
      "Requirement already satisfied: torch>=1.7 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from timm) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: pyyaml in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from timm) (0.34.4)\n",
      "Requirement already satisfied: typing-extensions in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torch>=1.7->timm) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torch>=1.7->timm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torch>=1.7->timm) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torch>=1.7->timm) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torch>=1.7->timm) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (78.1.1)\n",
      "Requirement already satisfied: wheel in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm) (0.45.1)\n",
      "Requirement already satisfied: filelock in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from huggingface-hub->timm) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2025.8.3)\n",
      "Requirement already satisfied: numpy in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torchvision->timm) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/james/anaconda3/envs/cv-competition/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "# PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ êµ¬í˜„\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "    \n",
    "    Args:\n",
    "        csv: CSV íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ì§€ íŒŒì¼ëª…ê³¼ ë¼ë²¨ ì •ë³´ í¬í•¨)\n",
    "        path: ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€í™˜ í•¨ìˆ˜ (ì„ íƒì‚¬í•­)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values  # CSV íŒŒì¼ì„ ì½ì–´ numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "        self.path = path                   # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        self.transform = transform         # ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"ë°ì´í„°ì…‹ì˜ ì „ì²´ ìƒ˜í”Œ ìˆ˜ ë°˜í™˜\"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì˜ ë°ì´í„° ìƒ˜í”Œ ë°˜í™˜\n",
    "        \n",
    "        Args:\n",
    "            idx: ë°ì´í„° ì¸ë±ìŠ¤\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (ì´ë¯¸ì§€ í…ì„œ, íƒ€ê²Ÿ ë¼ë²¨)\n",
    "        \"\"\"\n",
    "        name, target = self.df[idx]                                    # íŒŒì¼ëª…ê³¼ íƒ€ê²Ÿ ì¶”ì¶œ\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))     # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']                   # ì´ë¯¸ì§€ ë³€í™˜ ì ìš©\n",
    "            \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n",
      "ë°ì´í„° ê²½ë¡œ: /home/james/doc-classification/computervisioncompetition-cv3/data\n"
     ]
    }
   ],
   "source": [
    "# device ì„¤ì • - GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU ì‚¬ìš©\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# data config - ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "# ì´ë¯¸ ìœ„ì—ì„œ ì„¤ì •í•œ data_path ë³€ìˆ˜ë¥¼ ì‚¬ìš©\n",
    "print(f\"ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "\n",
    "# model config - ì‚¬ìš©í•  ëª¨ë¸ ì„¤ì •\n",
    "model_name = 'resnet34'  # ë‹¤ë¥¸ ì˜µì…˜: 'resnet50', 'efficientnet-b0', etc.\n",
    "\n",
    "# training config - í•™ìŠµ ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "img_size = 32        # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°\n",
    "LR = 1e-3           # í•™ìŠµë¥  (Learning Rate)\n",
    "EPOCHS = 1          # í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "BATCH_SIZE = 32     # ë°°ì¹˜ í¬ê¸°\n",
    "num_workers = 0     # ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# augmentationì„ ìœ„í•œ transform ì½”ë“œ\n",
    "trn_transform = A.Compose([\n",
    "    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    # images normalization\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: 1570, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°: 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset ì •ì˜ - í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "# ë¡œì»¬ data í´ë”ì˜ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ìƒì„±\n",
    "trn_dataset = ImageDataset(\n",
    "    os.path.join(data_path, \"train.csv\"),          # í•™ìŠµ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ\n",
    "    os.path.join(data_path, \"train/\"),             # í•™ìŠµ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
    "    transform=trn_transform                         # í•™ìŠµìš© ë°ì´í„° ë³€í™˜\n",
    ")\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    os.path.join(data_path, \"sample_submission.csv\"),  # í…ŒìŠ¤íŠ¸ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ\n",
    "    os.path.join(data_path, \"test/\"),                  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
    "    transform=tst_transform                             # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë³€í™˜\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: {len(trn_dataset)}, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°: {len(tst_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader ì •ì˜ - ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë°ì´í„° ë¡œë” ìƒì„±\n",
    "# í•™ìŠµìš© ë°ì´í„° ë¡œë”: ë°ì´í„° ìˆœì„œë¥¼ ì„ì–´ì„œ ë¡œë“œ\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,    # ë°°ì¹˜ í¬ê¸°\n",
    "    shuffle=True,             # ë°ì´í„° ìˆœì„œ ì„ê¸° (í•™ìŠµ ì‹œ ì¤‘ìš”)\n",
    "    num_workers=num_workers,  # ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ ìˆ˜\n",
    "    pin_memory=True,          # GPU ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    drop_last=False           # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì‘ì•„ë„ í¬í•¨\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë¡œë”: ë°ì´í„° ìˆœì„œë¥¼ ìœ ì§€í•˜ì—¬ ë¡œë“œ\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,    # ë°°ì¹˜ í¬ê¸°\n",
    "    shuffle=False,            # ë°ì´í„° ìˆœì„œ ìœ ì§€ (ì˜ˆì¸¡ ì‹œ ì¤‘ìš”)\n",
    "    num_workers=0,            # ì›Œì»¤ ìˆ˜ (ì˜ˆì¸¡ ì‹œì—ëŠ” ë³´í†µ 0ìœ¼ë¡œ ì„¤ì •)\n",
    "    pin_memory=True           # GPU ë©”ëª¨ë¦¬ ìµœì í™”\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /home/james/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "    ret['epoch'] = epoch\n",
    "\n",
    "    log = \"\"\n",
    "    for k, v in ret.items():\n",
    "      log += f\"{k}: {v:.4f}\\n\"\n",
    "    print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡  ìˆ˜í–‰\n",
    "preds_list = []\n",
    "\n",
    "model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • (ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™” ë¹„í™œì„±í™”)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë°°ì¹˜ë³„ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "for image, _ in tqdm(tst_loader, desc=\"ì¶”ë¡  ì§„í–‰ ì¤‘\"):\n",
    "    image = image.to(device)  # ì´ë¯¸ì§€ë¥¼ GPU/CPUë¡œ ì´ë™\n",
    "\n",
    "    with torch.no_grad():     # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½, ì†ë„ í–¥ìƒ)\n",
    "        preds = model(image)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    \n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ IDì™€ ì˜ˆì¸¡ëœ íƒ€ê²Ÿìœ¼ë¡œ ê²°ê³¼ DataFrame ìƒì„±\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list  # ì˜ˆì¸¡ ê²°ê³¼ë¡œ íƒ€ê²Ÿ ê°’ ì—…ë°ì´íŠ¸\n",
    "\n",
    "print(f\"ì˜ˆì¸¡ ì™„ë£Œ: {len(pred_df)}ê°œ ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ - sample_submission.csvì™€ ì˜ˆì¸¡ ê²°ê³¼ì˜ IDê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all(), \"IDê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\"\n",
    "print(\"âœ… ì œì¶œ íŒŒì¼ í˜•ì‹ ê²€ì¦ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "output_file = \"pred.csv\"\n",
    "pred_df.to_csv(output_file, index=False)\n",
    "print(f\"âœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_file}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv-competition",
   "language": "python",
   "name": "cv-competition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
