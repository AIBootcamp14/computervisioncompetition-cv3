#!/usr/bin/env python3
"""
í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°
Complete Pipeline Runner for Kaggle Document Classification Competition

Clean Code & Clean Architecture ì ìš©:
- Single Responsibility: ê° ë‹¨ê³„ë³„ ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
- Open/Closed: ìƒˆë¡œìš´ ë‹¨ê³„ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ì´ í™•ì¥ ê°€ëŠ¥
- Dependency Inversion: ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤ì— ì˜ì¡´
- Interface Segregation: ë‹¨ê³„ë³„ ì‘ì€ ì¸í„°í˜ì´ìŠ¤ë“¤ë¡œ ë¶„ë¦¬

ì „ì²´ íŒŒì´í”„ë¼ì¸:
01_EDA â†’ 02_preprocessing â†’ 03_modeling â†’ 04_training â†’ 05_evaluation â†’ 06_submission
"""

import os
import sys
import json
import time
import logging
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any, Protocol
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
import warnings
from datetime import datetime

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# ê° ë‹¨ê³„ë³„ ëª¨ë“ˆ import
try:
    # 01_EDA
    sys.path.append(str(current_dir / "01_EDA"))
    from competition_eda import CompetitionEDA
    
    # 02_preprocessing  
    sys.path.append(str(current_dir / "02_preprocessing"))
    from grandmaster_processor import GrandmasterProcessor
    
    # 03_modeling
    sys.path.append(str(current_dir / "03_modeling"))
    from kaggle_winner_training import KaggleWinnerPipeline
    
    # 04_training
    sys.path.append(str(current_dir / "04_training"))
    from grandmaster_train import GrandmasterExecutor
    
    # 05_evaluation
    sys.path.append(str(current_dir / "05_evaluation"))
    from main_evaluation import MainEvaluator
    
    # 06_submission
    sys.path.append(str(current_dir / "06_submission"))
    from final_submission import FinalSubmissionGenerator
    
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("ê° í´ë”ì˜ ì˜ì¡´ì„±ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)


class PipelineMode(Enum):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ëª¨ë“œ"""
    QUICK_TEST = "quick_test"          # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1ê°œ ëª¨ë¸, 1-fold)
    FULL_TRAINING = "full_training"    # ì „ì²´ í›ˆë ¨ (7ê°œ ëª¨ë¸, 5-fold)
    COMPETITION_READY = "competition_ready"  # ëŒ€íšŒ ì¤€ë¹„ (ìµœê³  ì„¤ì •)
    DEBUG = "debug"                    # ë””ë²„ê·¸ ëª¨ë“œ


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    mode: PipelineMode = PipelineMode.QUICK_TEST
    data_path: str = "/home/james/doc-classification/computervisioncompetition-cv3/data"
    output_dir: str = "/home/james/doc-classification/computervisioncompetition-cv3/workspaces/jaehong"
    experiment_name: str = field(default_factory=lambda: f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    skip_steps: List[str] = field(default_factory=list)
    verbose: bool = True
    save_intermediate: bool = True


class PipelineStep(ABC):
    """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, config: PipelineConfig):
        self.name = name
        self.config = config
        self.logger = logging.getLogger(f"Pipeline.{name}")
        
    @abstractmethod
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ê³„ ì‹¤í–‰"""
        pass
        
    @abstractmethod
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """ë‹¨ê³„ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        pass


class EDAStep(PipelineStep):
    """01_EDA ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("EDA", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """EDA ì‹¤í–‰"""
        self.logger.info("ğŸ” íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘")
        
        try:
            # EDA ì‹¤í–‰
            eda = CompetitionEDA(
                data_path=self.config.data_path,
                output_dir=Path(self.config.output_dir) / "01_EDA" / "eda_results"
            )
            
            # ì „ì²´ ë¶„ì„ ì‹¤í–‰
            results = eda.run_complete_analysis()
            
            context["eda_results"] = results
            context["eda_completed"] = True
            
            self.logger.info("âœ… EDA ì™„ë£Œ")
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ EDA ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """EDA ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        eda_results_path = Path(self.config.output_dir) / "01_EDA" / "eda_results"
        return eda_results_path.exists() and len(list(eda_results_path.glob("*.json"))) > 0


class PreprocessingStep(PipelineStep):
    """02_preprocessing ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("Preprocessing", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²˜ë¦¬ ì‹¤í–‰"""
        self.logger.info("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        
        try:
            # ì „ì²˜ë¦¬ ì‹¤í–‰
            processor = GrandmasterProcessor(
                data_path=self.config.data_path,
                output_dir=Path(self.config.output_dir) / "02_preprocessing",
                experiment_name=self.config.experiment_name
            )
            
            # EDA ê²°ê³¼ ë°˜ì˜
            if "eda_results" in context:
                processor.apply_eda_strategies(context["eda_results"])
            
            # ì „ì²˜ë¦¬ ì‹¤í–‰
            results = processor.run_complete_preprocessing()
            
            context["preprocessing_results"] = results
            context["preprocessing_completed"] = True
            
            self.logger.info("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        preprocessed_path = Path(self.config.output_dir) / "02_preprocessing"
        return preprocessed_path.exists() and len(list(preprocessed_path.glob("*.pkl"))) > 0


class ModelingStep(PipelineStep):
    """03_modeling ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("Modeling", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ëª¨ë¸ë§ ì‹¤í–‰"""
        self.logger.info("ğŸ§  ëª¨ë¸ë§ ì „ëµ ì‹¤í–‰ ì‹œì‘")
        
        try:
            # ëª¨ë¸ë§ ì „ëµ ì„¤ì •
            strategy = "single_best" if self.config.mode == PipelineMode.QUICK_TEST else "ensemble"
            target_score = 0.85 if self.config.mode == PipelineMode.QUICK_TEST else 0.95
            
            # íŒŒì´í”„ë¼ì¸ ìƒì„±
            pipeline = KaggleWinnerPipeline(
                strategy=strategy,
                target_score=target_score,
                experiment_name=self.config.experiment_name,
                fast_mode=(self.config.mode == PipelineMode.QUICK_TEST)
            )
            
            # ì„¤ì • ë° ì‹¤í–‰
            if pipeline.setup_components():
                context["modeling_pipeline"] = pipeline
                context["modeling_completed"] = True
                self.logger.info("âœ… ëª¨ë¸ë§ ì „ëµ ì„¤ì • ì™„ë£Œ")
            else:
                raise Exception("ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì‹¤íŒ¨")
                
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ë§ ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """ëª¨ë¸ë§ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        return False  # í•­ìƒ ì‹¤í–‰


class TrainingStep(PipelineStep):
    """04_training ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("Training", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """í›ˆë ¨ ì‹¤í–‰"""
        self.logger.info("ğŸ‹ï¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        try:
            # í›ˆë ¨ ì‹¤í–‰ê¸° ìƒì„±
            executor = GrandmasterExecutor(
                data_path=self.config.data_path,
                output_dir=Path(self.config.output_dir) / "04_training",
                experiment_name=self.config.experiment_name
            )
            
            # ëª¨ë“œë³„ ì„¤ì •
            if self.config.mode == PipelineMode.QUICK_TEST:
                results = executor.run_quick_test()
            elif self.config.mode == PipelineMode.FULL_TRAINING:
                results = executor.run_full_training()
            elif self.config.mode == PipelineMode.COMPETITION_READY:
                results = executor.run_competition_ready()
            else:  # DEBUG
                results = executor.run_debug()
            
            context["training_results"] = results
            context["training_completed"] = True
            
            self.logger.info("âœ… í›ˆë ¨ ì™„ë£Œ")
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """í›ˆë ¨ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        saved_models_path = Path(self.config.output_dir) / "04_training" / "saved_models"
        return saved_models_path.exists() and len(list(saved_models_path.glob("**/*.pt"))) > 0


class EvaluationStep(PipelineStep):
    """05_evaluation ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("Evaluation", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """í‰ê°€ ì‹¤í–‰"""
        self.logger.info("ğŸ“ˆ ëª¨ë¸ í‰ê°€ ì‹œì‘")
        
        try:
            # í‰ê°€ê¸° ìƒì„±
            evaluator = MainEvaluator(
                data_path=self.config.data_path,
                output_dir=Path(self.config.output_dir) / "05_evaluation",
                experiment_name=self.config.experiment_name
            )
            
            # í‰ê°€ ì‹¤í–‰
            results = evaluator.run_complete_evaluation()
            
            context["evaluation_results"] = results
            context["evaluation_completed"] = True
            
            self.logger.info("âœ… í‰ê°€ ì™„ë£Œ")
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """í‰ê°€ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        evaluation_path = Path(self.config.output_dir) / "05_evaluation"
        return evaluation_path.exists() and len(list(evaluation_path.glob("*.json"))) > 0


class SubmissionStep(PipelineStep):
    """06_submission ë‹¨ê³„"""
    
    def __init__(self, config: PipelineConfig):
        super().__init__("Submission", config)
        
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì œì¶œ íŒŒì¼ ìƒì„±"""
        self.logger.info("ğŸ“¤ ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì‹œì‘")
        
        try:
            # ì œì¶œ ìƒì„±ê¸° ìƒì„±
            generator = FinalSubmissionGenerator(
                data_path=self.config.data_path,
                output_dir=Path(self.config.output_dir) / "06_submission",
                experiment_name=self.config.experiment_name
            )
            
            # ì œì¶œ íŒŒì¼ ìƒì„±
            results = generator.generate_final_submission()
            
            context["submission_results"] = results
            context["submission_completed"] = True
            
            self.logger.info("âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ")
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
            
    def can_skip(self, context: Dict[str, Any]) -> bool:
        """ì œì¶œ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥ ì—¬ë¶€"""
        submission_path = Path(self.config.output_dir) / "06_submission" / "final_submissions"
        return submission_path.exists() and len(list(submission_path.glob("*.csv"))) > 0


class GrandmasterPipeline:
    """í†µí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.logger = self._setup_logging()
        self.steps = self._create_steps()
        self.context = {}
        
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger("GrandmasterPipeline")
        logger.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = Path(self.config.output_dir) / f"pipeline_{self.config.experiment_name}.log"
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        
        return logger
        
    def _create_steps(self) -> List[PipelineStep]:
        """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ìƒì„±"""
        return [
            EDAStep(self.config),
            PreprocessingStep(self.config),
            ModelingStep(self.config),
            TrainingStep(self.config),
            EvaluationStep(self.config),
            SubmissionStep(self.config)
        ]
        
    def run(self) -> bool:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        self.logger.info(f"ğŸ“‹ ëª¨ë“œ: {self.config.mode.value}")
        self.logger.info(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {self.config.data_path}")
        self.logger.info(f"ğŸ“‚ ì¶œë ¥ ê²½ë¡œ: {self.config.output_dir}")
        
        start_time = time.time()
        
        try:
            for i, step in enumerate(self.steps, 1):
                step_name = step.name
                
                # ê±´ë„ˆë›°ê¸° í™•ì¸
                if step_name.lower() in self.config.skip_steps:
                    self.logger.info(f"â­ï¸ {step_name} ë‹¨ê³„ ê±´ë„ˆë›°ê¸° (ì‚¬ìš©ì ì„¤ì •)")
                    continue
                    
                if step.can_skip(self.context):
                    self.logger.info(f"â­ï¸ {step_name} ë‹¨ê³„ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì™„ë£Œë¨)")
                    continue
                
                # ë‹¨ê³„ ì‹¤í–‰
                self.logger.info(f"ğŸ”„ [{i}/{len(self.steps)}] {step_name} ë‹¨ê³„ ì‹¤í–‰")
                step_start = time.time()
                
                self.context = step.execute(self.context)
                
                step_duration = time.time() - step_start
                self.logger.info(f"âœ… {step_name} ë‹¨ê³„ ì™„ë£Œ ({step_duration:.1f}ì´ˆ)")
                
                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                if self.config.save_intermediate:
                    self._save_intermediate_results(i, step_name)
            
            # ì „ì²´ ì™„ë£Œ
            total_duration = time.time() - start_time
            self.logger.info(f"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ({total_duration:.1f}ì´ˆ)")
            
            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            self._print_final_summary()
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False
            
    def _save_intermediate_results(self, step_num: int, step_name: str):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        try:
            results_file = Path(self.config.output_dir) / f"intermediate_results_step_{step_num}_{step_name}.json"
            
            # ë¯¼ê°í•œ ì •ë³´ ì œì™¸í•˜ê³  ì €ì¥
            safe_context = {}
            for key, value in self.context.items():
                if not key.endswith("_pipeline") and not key.endswith("_executor"):
                    safe_context[key] = str(value) if not isinstance(value, (dict, list)) else value
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(safe_context, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            self.logger.warning(f"ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            
    def _print_final_summary(self):
        """ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ† íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*60)
        
        # ì™„ë£Œëœ ë‹¨ê³„ë“¤
        completed_steps = [key.replace("_completed", "").title() 
                          for key, value in self.context.items() 
                          if key.endswith("_completed") and value]
        
        print(f"âœ… ì™„ë£Œëœ ë‹¨ê³„: {', '.join(completed_steps)}")
        
        # ì£¼ìš” ê²°ê³¼ë“¤
        if "training_results" in self.context:
            results = self.context["training_results"]
            if isinstance(results, dict) and "best_score" in results:
                print(f"ğŸ¯ ìµœê³  ì ìˆ˜: {results['best_score']:.4f}")
        
        if "submission_results" in self.context:
            print(f"ğŸ“¤ ì œì¶œ íŒŒì¼: {self.config.output_dir}/06_submission/final_submissions/")
        
        print(f"ğŸ“ ì „ì²´ ê²°ê³¼: {self.config.output_dir}")
        print("="*60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ğŸ† í†µí•© íŒŒì´í”„ë¼ì¸")
    
    parser.add_argument(
        "--mode", 
        choices=["quick_test", "full_training", "competition_ready", "debug"],
        default="quick_test",
        help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ"
    )
    
    parser.add_argument(
        "--data-path",
        default="/home/james/doc-classification/computervisioncompetition-cv3/data",
        help="ë°ì´í„° ê²½ë¡œ"
    )
    
    parser.add_argument(
        "--output-dir",
        default="/home/james/doc-classification/computervisioncompetition-cv3/workspaces/jaehong",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    
    parser.add_argument(
        "--experiment-name",
        help="ì‹¤í—˜ ì´ë¦„ (ê¸°ë³¸ê°’: ìë™ ìƒì„±)"
    )
    
    parser.add_argument(
        "--skip-steps",
        nargs="+",
        help="ê±´ë„ˆë›¸ ë‹¨ê³„ë“¤ (eda, preprocessing, modeling, training, evaluation, submission)"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = PipelineConfig(
        mode=PipelineMode(args.mode),
        data_path=args.data_path,
        output_dir=args.output_dir,
        experiment_name=args.experiment_name or f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        skip_steps=args.skip_steps or [],
        verbose=args.verbose
    )
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(config.output_dir).mkdir(parents=True, exist_ok=True)
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = GrandmasterPipeline(config)
    success = pipeline.run()
    
    if success:
        print("\nğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ!")
        sys.exit(0)
    else:
        print("\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨!")
        sys.exit(1)


if __name__ == "__main__":
    main()
