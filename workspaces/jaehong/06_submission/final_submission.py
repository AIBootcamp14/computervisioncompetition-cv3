"""
ğŸ† Final Submission System
ì‹œë‹ˆì–´ ê·¸ëœë“œë§ˆìŠ¤í„° ìˆ˜ì¤€ì˜ ìµœì¢… ì œì¶œ ì‹œìŠ¤í…œ

Features:
- 05_evaluation ê²°ê³¼ í™œìš©
- TTA ê¸°ë°˜ ìµœì¢… ì˜ˆì¸¡
- ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”
- ì™„ë²½í•œ ê²€ì¦ ë° ë¶„ì„
"""

import argparse
import warnings
from pathlib import Path
import torch
import pandas as pd
import numpy as np
from datetime import datetime

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# 05_evaluation ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.insert(0, str(Path(__file__).parent.parent / "05_evaluation"))
from tta_predictor import TTAPredictor
from evaluation_config import EvaluationConfigManager

# 04_training ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.insert(0, str(Path(__file__).parent.parent / "04_training"))
from model import DocumentClassifier
from utils import set_seed, get_gpu_info, optimize_gpu_settings

# ë¡œì»¬ ëª¨ë“ˆ
from submission_generator import SubmissionGenerator


def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ğŸ† Final Submission Generation")
    
    # í•„ìˆ˜ ì¸ìˆ˜
    parser.add_argument("--training_experiment", type=str, required=True,
                       help="04_training ì‹¤í—˜ ì´ë¦„")
    parser.add_argument("--submission_name", type=str, default="final_submission",
                       help="ì œì¶œ íŒŒì¼ ì´ë¦„")
    
    # TTA ì„¤ì •
    parser.add_argument("--enable_tta", action="store_true", default=True,
                       help="TTA í™œì„±í™”")
    parser.add_argument("--n_tta", type=int, default=8,
                       help="TTA ìˆ˜")
    parser.add_argument("--tta_weights", type=str, default=None,
                       help="TTA ê°€ì¤‘ì¹˜ (ì½¤ë§ˆë¡œ êµ¬ë¶„)")
    
    # ì•™ìƒë¸” ì„¤ì •
    parser.add_argument("--enable_ensemble", action="store_true",
                       help="ì•™ìƒë¸” í™œì„±í™”")
    parser.add_argument("--ensemble_files", type=str, nargs='+',
                       help="ì•™ìƒë¸”í•  í™•ë¥  íŒŒì¼ë“¤")
    parser.add_argument("--ensemble_weights", type=str, default=None,
                       help="ì•™ìƒë¸” ê°€ì¤‘ì¹˜ (ì½¤ë§ˆë¡œ êµ¬ë¶„)")
    
    # ì¶œë ¥ ì„¤ì •
    parser.add_argument("--output_dir", type=str, default="final_submissions",
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--create_analysis", action="store_true", default=True,
                       help="ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
    
    # ê¸°íƒ€
    parser.add_argument("--seed", type=int, default=42,
                       help="ëœë¤ ì‹œë“œ")
    parser.add_argument("--batch_size", type=int, default=32,
                       help="ë°°ì¹˜ í¬ê¸°")
    
    return parser.parse_args()


def load_trained_model(model_path: str, model_config: dict, device: str) -> torch.nn.Module:
    """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ"""
    
    print(f"ğŸ§  í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # ëª¨ë¸ ìƒì„±
    model = DocumentClassifier(
        architecture=model_config.get('architecture', 'efficientnetv2_s'),
        num_classes=model_config.get('num_classes', 17),
        dropout_rate=model_config.get('dropout_rate', 0.3)
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    model.eval()
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ:")
    print(f"   ì•„í‚¤í…ì²˜: {model_config.get('architecture', 'efficientnetv2_s')}")
    print(f"   ìµœê³  F1: {checkpoint.get('best_score', 'N/A')}")
    
    return model


def create_single_model_submission(
    args,
    eval_config_manager: EvaluationConfigManager,
    device: str
) -> dict:
    """ë‹¨ì¼ ëª¨ë¸ ì œì¶œ íŒŒì¼ ìƒì„±"""
    
    print(f"ğŸ¯ ë‹¨ì¼ ëª¨ë¸ ì œì¶œ íŒŒì¼ ìƒì„±...")
    
    # ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    model_info = eval_config_manager.get_model_info()
    data_info = eval_config_manager.get_data_info()
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_trained_model(
        model_info['model_path'],
        {
            'architecture': model_info['architecture'],
            'num_classes': model_info['num_classes'],
            'dropout_rate': 0.3
        },
        device
    )
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
    sample_df = pd.read_csv(data_info['data_root'] + "/sample_submission.csv")
    test_image_paths = [
        str(Path(data_info['data_root']) / "test" / img_id) 
        for img_id in sample_df['ID']
    ]
    
    if args.enable_tta:
        # TTA ì˜ˆì¸¡
        print(f"ğŸ”® TTA ì˜ˆì¸¡ ìˆ˜í–‰...")
        
        # TTA ê°€ì¤‘ì¹˜ íŒŒì‹±
        tta_weights = None
        if args.tta_weights:
            tta_weights = [float(w.strip()) for w in args.tta_weights.split(',')]
        
        tta_predictor = TTAPredictor(
            model=model,
            device=device,
            tta_weights=tta_weights
        )
        
        predictions, probabilities, tta_stats = tta_predictor.predict_with_tta(
            image_paths=test_image_paths,
            image_size=model_info['image_size'],
            batch_size=args.batch_size
        )
        
        confidence_scores = np.max(probabilities, axis=1)
        
        print(f"âœ… TTA ì˜ˆì¸¡ ì™„ë£Œ:")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {tta_stats['mean_confidence']:.4f}")
        
    else:
        # ë‹¨ì¼ ì˜ˆì¸¡ (TTA ì—†ìŒ)
        print(f"ğŸ¯ ë‹¨ì¼ ì˜ˆì¸¡ ìˆ˜í–‰...")
        
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ TTA 1ê°œë§Œ ì‚¬ìš©
        tta_predictor = TTAPredictor(model=model, device=device)
        predictions, probabilities, _ = tta_predictor.predict_with_tta(
            image_paths=test_image_paths,
            image_size=model_info['image_size'],
            batch_size=args.batch_size
        )
        confidence_scores = np.max(probabilities, axis=1)
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission_generator = SubmissionGenerator(
        sample_submission_path=str(Path(data_info['data_root']) / "sample_submission.csv"),
        class_names=data_info['class_names'],
        class_weights=data_info['class_weights']
    )
    
    return {
        'predictions': predictions,
        'probabilities': probabilities,
        'confidence_scores': confidence_scores,
        'submission_generator': submission_generator,
        'model_info': model_info
    }


def create_ensemble_submission(
    args,
    submission_generator: SubmissionGenerator
) -> dict:
    """ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„±"""
    
    print(f"ğŸ­ ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„±...")
    
    # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ íŒŒì‹±
    weights = None
    if args.ensemble_weights:
        weights = [float(w.strip()) for w in args.ensemble_weights.split(',')]
    
    return submission_generator.create_ensemble_submission(
        prediction_files=args.ensemble_files,
        weights=weights,
        experiment_name=f"{args.submission_name}_ensemble",
        output_dir=Path(args.output_dir)
    )


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ† Final Submission Generation")
    print("=" * 60)
    
    # ì¸ìˆ˜ íŒŒì‹±
    args = parse_args()
    
    # ì‹œìŠ¤í…œ ìµœì í™”
    optimize_gpu_settings()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ì¬í˜„ì„± ë³´ì¥
    set_seed(args.seed)
    
    # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ
    workspace_root = Path(__file__).parent.parent
    
    # í‰ê°€ ì„¤ì • ê´€ë¦¬ì ìƒì„±
    eval_config_manager = EvaluationConfigManager(
        str(workspace_root), 
        args.training_experiment
    )
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ† ìµœì¢… ì œì¶œ ì„¤ì •:")
    print(f"   í›ˆë ¨ ì‹¤í—˜: {args.training_experiment}")
    print(f"   ì œì¶œ ì´ë¦„: {args.submission_name}")
    print(f"   TTA: {'âœ…' if args.enable_tta else 'âŒ'} ({args.n_tta if args.enable_tta else 0}ê°œ)")
    print(f"   ì•™ìƒë¸”: {'âœ…' if args.enable_ensemble else 'âŒ'}")
    print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    if args.enable_ensemble and args.ensemble_files:
        # ì•™ìƒë¸” ì œì¶œ
        print(f"   ì•™ìƒë¸” íŒŒì¼: {len(args.ensemble_files)}ê°œ")
        
        # ì„ì‹œë¡œ submission_generator ìƒì„±
        data_info = eval_config_manager.get_data_info()
        submission_generator = SubmissionGenerator(
            sample_submission_path=str(Path(data_info['data_root']) / "sample_submission.csv"),
            class_names=data_info['class_names'],
            class_weights=data_info['class_weights']
        )
        
        submission_info = create_ensemble_submission(args, submission_generator)
        
    else:
        # ë‹¨ì¼ ëª¨ë¸ ì œì¶œ
        result = create_single_model_submission(args, eval_config_manager, device)
        
        # ì œì¶œ íŒŒì¼ ìƒì„±
        submission_info = result['submission_generator'].create_submission(
            predictions=result['predictions'],
            probabilities=result['probabilities'],
            confidence_scores=result['confidence_scores'],
            experiment_name=args.submission_name,
            output_dir=output_dir,
            save_probabilities=True,
            create_analysis=args.create_analysis
        )
    
    # ìµœì¢… ìš”ì•½
    print(f"\nğŸ ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"   ì œì¶œ íŒŒì¼: {submission_info['submission_file']}")
    print(f"   ì˜ˆì¸¡ ìˆ˜: {submission_info['prediction_count']}")
    print(f"   ì‚¬ìš©ëœ í´ë˜ìŠ¤: {submission_info['unique_predictions']}ê°œ")
    
    if 'confidence_stats' in submission_info:
        conf_stats = submission_info['confidence_stats']
        print(f"   í‰ê·  ì‹ ë¢°ë„: {conf_stats['mean_confidence']:.4f}")
        print(f"   ë†’ì€ ì‹ ë¢°ë„ ì˜ˆì¸¡: {conf_stats['high_confidence_count']}ê°œ")
    
    # Kaggle ì œì¶œ ì•ˆë‚´
    print(f"\nğŸš€ Kaggle ì œì¶œ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"   1. íŒŒì¼ ë‹¤ìš´ë¡œë“œ: {submission_info['submission_file']}")
    print(f"   2. Kaggle ì—…ë¡œë“œ")
    print(f"   3. ì„±ëŠ¥ í™•ì¸")
    
    # ì„±ëŠ¥ ì˜ˆìƒ (í›ˆë ¨ ê²°ê³¼ ê¸°ë°˜)
    if not args.enable_ensemble:
        model_f1 = result['model_info']['best_f1']
        if model_f1 > 0.85:
            print(f"   ğŸ¯ ì˜ˆìƒ LB ì ìˆ˜: ë§¤ìš° ë†’ìŒ (0.80+)")
        elif model_f1 > 0.75:
            print(f"   ğŸ¯ ì˜ˆìƒ LB ì ìˆ˜: ë†’ìŒ (0.70+)")
        else:
            print(f"   ğŸ¯ ì˜ˆìƒ LB ì ìˆ˜: ë³´í†µ (0.60+)")
    
    return submission_info


if __name__ == "__main__":
    try:
        submission_info = main()
        print("\nâœ… ìµœì¢… ì œì¶œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì„±ê³µ!")
        
    except Exception as e:
        print(f"\nâŒ ìµœì¢… ì œì¶œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
