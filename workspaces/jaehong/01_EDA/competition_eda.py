"""
Competition EDA - ë¬¸ì„œ ë¶„ë¥˜ ëŒ€íšŒìš© íƒìƒ‰ì  ë°ì´í„° ë¶„ì„

Clean Code & Clean Architecture ì ìš©:
- Single Responsibility Principle: ê° ë¶„ì„ ê¸°ëŠ¥ë³„ë¡œ í´ë˜ìŠ¤/ë©”ì„œë“œ ë¶„ë¦¬
- Open/Closed Principle: ìƒˆë¡œìš´ ë¶„ì„ ë°©ë²• ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ì´ í™•ì¥ ê°€ëŠ¥
- Dependency Inversion: ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤ì— ì˜ì¡´
- Interface Segregation: íŠ¹ì • ìš©ë„ì— ë§ëŠ” ì‘ì€ ì¸í„°í˜ì´ìŠ¤ë“¤ë¡œ ë¶„ë¦¬

ëŒ€íšŒ ì „ëµ ì¤‘ì‹¬ì˜ EDA:
1. Train/Test ë°ì´í„° ì°¨ì´ ë¶„ì„ (í•µì‹¬!)
2. ì´ì§ˆì  ì´ë¯¸ì§€ íƒì§€ (ì°¨ëŸ‰ ëŒ€ì‹œë³´ë“œ, ë²ˆí˜¸íŒ)
3. íšŒì „/ë¸”ëŸ¬/ë…¸ì´ì¦ˆ ë¶„ì„
4. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë° Augmentation ì „ëµ
5. ìµœì  Resize ì „ëµ ë„ì¶œ
"""

import os
import sys
from pathlib import Path
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional, Any, Protocol
import warnings

# Data & Math
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Image Processing
import cv2
from PIL import Image, ImageFilter, ImageEnhance, ImageOps
import albumentations as A

# Visualization
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ì—ì„œ ì‚¬ìš©
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.patches as patches
from matplotlib.gridspec import GridSpec

# Utils
import random
from collections import Counter, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import json

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
import matplotlib.font_manager as fm

def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì •"""
    system = platform.system()
    
    if system == 'Windows':
        # Windows ì‹œìŠ¤í…œ
        font_candidates = ['Malgun Gothic', 'Arial Unicode MS', 'SimHei']
    elif system == 'Darwin':  # macOS
        font_candidates = ['AppleGothic', 'Arial Unicode MS']
    else:  # Linux
        font_candidates = ['Noto Sans CJK KR', 'DejaVu Sans', 'Liberation Sans']
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì°¾ê¸°
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    selected_font = 'DejaVu Sans'  # ê¸°ë³¸ê°’
    for font in font_candidates:
        if font in available_fonts:
            selected_font = font
            break
    
    plt.rcParams['font.family'] = selected_font
    plt.rcParams['axes.unicode_minus'] = False
    print(f"ğŸ¨ í°íŠ¸ ì„¤ì •: {selected_font}")

# í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤í–‰
setup_korean_font()

# ì‹œë“œ ê³ ì • (ì¬í˜„ê°€ëŠ¥í•œ ë¶„ì„)
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)


@dataclass
class ImageMetrics:
    """ì´ë¯¸ì§€ í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    brightness: float
    contrast: float
    sharpness: float
    noise_level: float
    rotation_angle: float
    aspect_ratio: float
    file_size_kb: float
    width: int
    height: int
    
    def to_dict(self) -> Dict[str, float]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'brightness': self.brightness,
            'contrast': self.contrast,
            'sharpness': self.sharpness,
            'noise_level': self.noise_level,
            'rotation_angle': self.rotation_angle,
            'aspect_ratio': self.aspect_ratio,
            'file_size_kb': self.file_size_kb,
            'width': self.width,
            'height': self.height
        }


class ImageAnalyzer(ABC):
    """ì´ë¯¸ì§€ ë¶„ì„ì„ ìœ„í•œ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def analyze_image(self, image_path: Path) -> Optional[ImageMetrics]:
        """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë©”íŠ¸ë¦­ì„ ë°˜í™˜"""
        pass


class DocumentImageAnalyzer(ImageAnalyzer):
    """
    ë¬¸ì„œ ì´ë¯¸ì§€ ì „ìš© ë¶„ì„ê¸°
    
    ì±…ì„:
    - ë¬¸ì„œ ì´ë¯¸ì§€ì˜ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
    - íšŒì „ ê°ë„ íƒì§€ (Hough Transform ì‚¬ìš©)
    - ë…¸ì´ì¦ˆ ë ˆë²¨ ì¸¡ì •
    """
    
    def analyze_image(self, image_path: Path) -> Optional[ImageMetrics]:
        """
        ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ì„
        
        Args:
            image_path: ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ
            
        Returns:
            ImageMetrics ê°ì²´ ë˜ëŠ” None (ë¶„ì„ ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_bgr = cv2.imread(str(image_path))
            if img_bgr is None:
                return None
                
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
            
            # ê¸°ë³¸ ì •ë³´
            height, width = img_gray.shape
            file_size_kb = image_path.stat().st_size / 1024
            aspect_ratio = width / height
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            brightness = self._calculate_brightness(img_gray)
            contrast = self._calculate_contrast(img_gray)
            sharpness = self._calculate_sharpness(img_gray)
            noise_level = self._calculate_noise_level(img_gray)
            rotation_angle = self._detect_rotation_angle(img_gray)
            
            return ImageMetrics(
                brightness=brightness,
                contrast=contrast,
                sharpness=sharpness,
                noise_level=noise_level,
                rotation_angle=rotation_angle,
                aspect_ratio=aspect_ratio,
                file_size_kb=file_size_kb,
                width=width,
                height=height
            )
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨ {image_path}: {str(e)}")
            return None
    
    def _calculate_brightness(self, img_gray: np.ndarray) -> float:
        """ë°ê¸° ê³„ì‚°"""
        return np.mean(img_gray)
    
    def _calculate_contrast(self, img_gray: np.ndarray) -> float:
        """ëŒ€ë¹„ ê³„ì‚° (í‘œì¤€í¸ì°¨ ì‚¬ìš©)"""
        return np.std(img_gray)
    
    def _calculate_sharpness(self, img_gray: np.ndarray) -> float:
        """ì„ ëª…ë„ ê³„ì‚° (Laplacian ë¶„ì‚° ì‚¬ìš©)"""
        laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)
        return laplacian.var()
    
    def _calculate_noise_level(self, img_gray: np.ndarray) -> float:
        """
        ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°
        Gaussian blur í›„ ì›ë³¸ê³¼ì˜ ì°¨ì´ë¡œ ë…¸ì´ì¦ˆ ì¶”ì •
        """
        blurred = cv2.GaussianBlur(img_gray, (5, 5), 0)
        noise = img_gray.astype(np.float32) - blurred.astype(np.float32)
        return np.std(noise)
    
    def _detect_rotation_angle(self, img_gray: np.ndarray) -> float:
        """
        Hough Transformì„ ì‚¬ìš©í•œ íšŒì „ ê°ë„ íƒì§€
        
        Returns:
            íšŒì „ ê°ë„ (ë„ ë‹¨ìœ„, -45 ~ 45 ë²”ìœ„)
        """
        try:
            # ì—£ì§€ ê²€ì¶œ
            edges = cv2.Canny(img_gray, 50, 150, apertureSize=3)
            
            # Hough Line Transform
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            if lines is None:
                return 0.0
            
            # ê°ë„ ê³„ì‚°
            angles = []
            for rho, theta in lines[:20]:  # ìƒìœ„ 20ê°œ ë¼ì¸ë§Œ ì‚¬ìš©
                angle = np.degrees(theta) - 90
                if -45 <= angle <= 45:
                    angles.append(angle)
            
            if angles:
                return np.median(angles)
            else:
                return 0.0
                
        except Exception:
            return 0.0


class DatasetAnalyzer:
    """
    ë°ì´í„°ì…‹ ì „ì²´ ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    
    ì±…ì„:
    - Train/Test ë°ì´í„° ë¡œë“œ ë° ê´€ë¦¬
    - í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    - ì´ë¯¸ì§€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¹„êµ
    """
    
    def __init__(self, data_root: Path):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_root: ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        """
        self.data_root = Path(data_root)
        self.train_dir = self.data_root / "train"
        self.test_dir = self.data_root / "test"
        self.train_csv = self.data_root / "train.csv"
        self.meta_csv = self.data_root / "meta.csv"
        self.sample_submission_csv = self.data_root / "sample_submission.csv"
        
        # ë°ì´í„° ë¡œë“œ
        self.train_df = pd.read_csv(self.train_csv)
        self.meta_df = pd.read_csv(self.meta_csv)
        self.sample_submission = pd.read_csv(self.sample_submission_csv)
        
        # í´ë˜ìŠ¤ ë§¤í•‘
        self.class_mapping = dict(zip(self.meta_df['target'], self.meta_df['class_name']))
        
        # ì´ë¯¸ì§€ ë¶„ì„ê¸°
        self.image_analyzer = DocumentImageAnalyzer()
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:")
        print(f"  â€¢ í•™ìŠµ ë°ì´í„°: {len(self.train_df):,}ê°œ")
        print(f"  â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.sample_submission):,}ê°œ")
        print(f"  â€¢ í´ë˜ìŠ¤ ìˆ˜: {len(self.class_mapping)}ê°œ")
    
    def get_image_paths(self, dataset_type: str) -> List[Path]:
        """
        ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        Args:
            dataset_type: 'train' ë˜ëŠ” 'test'
        """
        if dataset_type == 'train':
            return [self.train_dir / img_id for img_id in self.train_df['ID']]
        elif dataset_type == 'test':
            return [self.test_dir / img_id for img_id in self.sample_submission['ID']]
        else:
            raise ValueError("dataset_typeì€ 'train' ë˜ëŠ” 'test'ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    def analyze_images_batch(self, image_paths: List[Path], max_workers: int = 4) -> List[ImageMetrics]:
        """
        ì´ë¯¸ì§€ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„
        
        Args:
            image_paths: ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
            
        Returns:
            ImageMetrics ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            future_to_path = {
                executor.submit(self.image_analyzer.analyze_image, path): path 
                for path in image_paths
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in tqdm(as_completed(future_to_path), total=len(image_paths), desc="ì´ë¯¸ì§€ ë¶„ì„ ì¤‘"):
                result = future.result()
                if result is not None:
                    results.append(result)
        
        return results


class CompetitionEDA:
    """
    ëŒ€íšŒìš© EDA ë©”ì¸ í´ë˜ìŠ¤
    
    ì±…ì„:
    - ì „ì²´ EDA í”„ë¡œì„¸ìŠ¤ ì¡°ìœ¨
    - ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
    - ëŒ€íšŒ ì „ëµ ì œì•ˆ
    """
    
    def __init__(self, data_root: Path):
        """ì´ˆê¸°í™”"""
        self.data_root = Path(data_root)
        self.dataset_analyzer = DatasetAnalyzer(data_root)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = Path(__file__).parent / "eda_results"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('seaborn-v0_8-darkgrid')
        sns.set_palette("husl")
        
        print(f"ğŸ† Competition EDA ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.output_dir}")
    
    def run_complete_analysis(self):
        """
        ëŒ€íšŒ ì „ëµì— ë§ëŠ” í¬ê´„ì ì¸ EDA ì‹¤í–‰
        
        ë¶„ì„ ìˆœì„œ:
        1. ê¸°ë³¸ ë°ì´í„° íƒìƒ‰
        2. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ & ì „ëµ ì œì•ˆ
        3. Train/Test ì´ë¯¸ì§€ ì°¨ì´ ë¶„ì„ (í•µì‹¬!)
        4. ì´ì§ˆì  ì´ë¯¸ì§€ íƒì§€
        5. íšŒì „/ë¸”ëŸ¬/ë…¸ì´ì¦ˆ ë¶„ì„
        6. ì´ë¯¸ì§€ í¬ê¸°/ì¢…íš¡ë¹„ ë¶„ì„
        7. ìµœì¢… ëŒ€íšŒ ì „ëµ ì œì•ˆ
        """
        print("=== ğŸš€ Competition EDA ì‹œì‘ ===\n")
        
        try:
            # 1. ê¸°ë³¸ ë°ì´í„° íƒìƒ‰
            self._basic_data_exploration()
            
            # 2. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„
            self._analyze_class_imbalance()
            
            # 3. Train/Test ì°¨ì´ ë¶„ì„ (ëŒ€íšŒ í•µì‹¬!)
            self._analyze_train_test_differences()
            
            # 4. ì´ì§ˆì  ì´ë¯¸ì§€ íƒì§€
            self._detect_anomalous_images()
            
            # 5. ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„
            self._analyze_image_quality()
            
            # 6. í¬ê¸°/ì¢…íš¡ë¹„ ë¶„ì„
            self._analyze_image_dimensions()
            
            # 7. ìµœì¢… ì „ëµ ì œì•ˆ
            self._generate_competition_strategy()
            
            print("\n=== âœ… EDA ë¶„ì„ ì™„ë£Œ ===")
            print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ê°€ {self.output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ EDA ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise
    
    def _basic_data_exploration(self):
        """ê¸°ë³¸ ë°ì´í„° íƒìƒ‰"""
        print("=== ğŸ“Š 1. ê¸°ë³¸ ë°ì´í„° íƒìƒ‰ ===")
        
        train_df = self.dataset_analyzer.train_df
        meta_df = self.dataset_analyzer.meta_df
        class_mapping = self.dataset_analyzer.class_mapping
        
        # ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´
        print(f"ğŸ“ˆ ë°ì´í„°ì…‹ í¬ê¸°:")
        print(f"  â€¢ í•™ìŠµ ë°ì´í„°: {len(train_df):,}ê°œ")
        print(f"  â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.dataset_analyzer.sample_submission):,}ê°œ")
        print(f"  â€¢ ì´ í´ë˜ìŠ¤ ìˆ˜: {len(class_mapping)}ê°œ")
        print(f"  â€¢ Train/Test ë¹„ìœ¨: 1:{len(self.dataset_analyzer.sample_submission)/len(train_df):.1f}")
        
        # í´ë˜ìŠ¤ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“‹ í´ë˜ìŠ¤ ëª©ë¡:")
        for target, class_name in class_mapping.items():
            print(f"  {target:2d}: {class_name}")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        train_files = list(self.dataset_analyzer.train_dir.glob("*.jpg"))
        test_files = list(self.dataset_analyzer.test_dir.glob("*.jpg"))
        
        print(f"\nğŸ“ íŒŒì¼ ì •ë³´:")
        print(f"  â€¢ í•™ìŠµ ì´ë¯¸ì§€ íŒŒì¼: {len(train_files):,}ê°œ")
        print(f"  â€¢ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼: {len(test_files):,}ê°œ")
        
        # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
        train_ids_csv = set(train_df['ID'].str.replace('.jpg', ''))
        train_ids_files = set([f.stem for f in train_files])
        missing_files = train_ids_csv - train_ids_files
        
        print(f"\nğŸ” ë°ì´í„° ì¼ê´€ì„±:")
        print(f"  â€¢ CSVì— ìˆì§€ë§Œ íŒŒì¼ì´ ì—†ëŠ” ê²ƒ: {len(missing_files)}ê°œ")
        if missing_files:
            print(f"  â€¢ ëˆ„ë½ íŒŒì¼ ì˜ˆì‹œ: {list(missing_files)[:3]}")
        
        print()
    
    def _analyze_class_imbalance(self):
        """í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ë° ì „ëµ ì œì•ˆ"""
        print("=== âš–ï¸ 2. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ===")
        
        train_df = self.dataset_analyzer.train_df
        class_mapping = self.dataset_analyzer.class_mapping
        
        # í´ë˜ìŠ¤ ë¶„í¬ ê³„ì‚°
        class_counts = train_df['target'].value_counts().sort_index()
        total_samples = len(train_df)
        
        print("ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬:")
        imbalance_data = []
        for target in sorted(class_mapping.keys()):
            count = class_counts.get(target, 0)
            percentage = (count / total_samples) * 100
            class_name = class_mapping[target]
            print(f"  {target:2d}: {count:3d}ê°œ ({percentage:5.1f}%) - {class_name[:40]}")
            imbalance_data.append({
                'target': target,
                'count': count,
                'percentage': percentage,
                'class_name': class_name
            })
        
        # ë¶ˆê· í˜• ë©”íŠ¸ë¦­ ê³„ì‚°
        max_count = class_counts.max()
        min_count = class_counts.min()
        imbalance_ratio = max_count / min_count
        std_dev = class_counts.std()
        cv = std_dev / class_counts.mean()  # ë³€ë™ê³„ìˆ˜
        
        print(f"\nğŸ“ˆ ë¶ˆê· í˜• ë©”íŠ¸ë¦­:")
        print(f"  â€¢ ìµœëŒ€ í´ë˜ìŠ¤: {max_count}ê°œ")
        print(f"  â€¢ ìµœì†Œ í´ë˜ìŠ¤: {min_count}ê°œ") 
        print(f"  â€¢ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1")
        print(f"  â€¢ í‘œì¤€í¸ì°¨: {std_dev:.1f}")
        print(f"  â€¢ ë³€ë™ê³„ìˆ˜: {cv:.3f}")
        
        # ë¶ˆê· í˜• ì‹¬ê°ë„ í‰ê°€ ë° ì „ëµ ì œì•ˆ
        if imbalance_ratio > 10:
            severity = "ğŸ”´ ì‹¬ê°"
            strategy = "SMOTE + Focal Loss + Class Weights"
        elif imbalance_ratio > 5:
            severity = "ğŸŸ¡ ë³´í†µ" 
            strategy = "Focal Loss + Stratified Sampling"
        else:
            severity = "ğŸŸ¢ ê²½ë¯¸"
            strategy = "Stratified K-Foldë¡œ ì¶©ë¶„"
        
        print(f"  â€¢ ë¶ˆê· í˜• ì‹¬ê°ë„: {severity}")
        print(f"  â€¢ ê¶Œì¥ ì „ëµ: {strategy}")
        
        # ì‹œê°í™”
        self._plot_class_distribution(imbalance_data)
        
        # Stratified sampling ê°€ì¤‘ì¹˜ ê³„ì‚°
        self._calculate_class_weights(class_counts)
        
        print()
    
    def _plot_class_distribution(self, imbalance_data: List[Dict]):
        """í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” (í•œê¸€ ì§€ì›)"""
        # í°íŠ¸ ì¬ì„¤ì • (ì°¨íŠ¸ë³„ë¡œ í™•ì‹¤íˆ ì ìš©)
        setup_korean_font()
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
        
        # ë°ì´í„° ì¤€ë¹„
        targets = [d['target'] for d in imbalance_data]
        counts = [d['count'] for d in imbalance_data]
        class_names = [d['class_name'] for d in imbalance_data]
        
        # ë§‰ëŒ€ ê·¸ë˜í”„
        colors = plt.cm.viridis(np.linspace(0, 1, len(targets)))
        bars = ax1.bar(targets, counts, color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
        ax1.set_xlabel('Class ID', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Image Count', fontsize=12, fontweight='bold')
        ax1.set_title('Class Distribution', fontsize=16, fontweight='bold', pad=20)
        ax1.grid(True, alpha=0.3)
        ax1.set_xticks(targets)
        
        # ë§‰ëŒ€ ìœ„ì— ìˆ˜ì¹˜ í‘œì‹œ
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + max(counts)*0.01,
                    f'{count}', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        # ì›í˜• ê·¸ë˜í”„ - í´ë˜ìŠ¤ëª… í¬í•¨
        # í´ë˜ìŠ¤ëª…ì„ ì¶•ì•½í•´ì„œ í‘œì‹œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¦¼)
        short_labels = []
        for i, (target, name) in enumerate(zip(targets, class_names)):
            if len(name) > 20:
                short_name = name[:17] + "..."
            else:
                short_name = name
            short_labels.append(f"{target}: {short_name}")
        
        colors_pie = plt.cm.Set3(np.linspace(0, 1, len(targets)))
        wedges, texts, autotexts = ax2.pie(counts, labels=None, autopct='%1.1f%%', 
                                          colors=colors_pie, startangle=90,
                                          textprops={'fontsize': 9})
        ax2.set_title('Class Ratio Distribution', fontsize=16, fontweight='bold', pad=20)
        
        # ë²”ë¡€ ì¶”ê°€ (ì›í˜• ê·¸ë˜í”„ ì˜†ì—)
        ax2.legend(wedges, short_labels, title="Classes", loc="center left", 
                  bbox_to_anchor=(1, 0, 0.5, 1), fontsize=8, title_fontsize=10)
        
        plt.tight_layout()
        
        # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì €ì¥
        plt.savefig(self.output_dir / 'class_distribution.png', 
                   dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        plt.close()  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ figure ë‹«ê¸°
        
        print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ì°¨íŠ¸ ì €ì¥: {self.output_dir / 'class_distribution.png'}")
        
        # í´ë˜ìŠ¤ë³„ ìƒì„¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œë„ ì €ì¥
        self._save_class_info_text(imbalance_data)
    
    def _save_class_info_text(self, imbalance_data: List[Dict]):
        """í´ë˜ìŠ¤ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ (í•œê¸€ ê¹¨ì§ ë°©ì§€)"""
        try:
            with open(self.output_dir / 'class_distribution.txt', 'w', encoding='utf-8') as f:
                f.write("ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬ ìƒì„¸ ì •ë³´\n")
                f.write("=" * 50 + "\n\n")
                
                total_samples = sum(d['count'] for d in imbalance_data)
                f.write(f"ì´ ìƒ˜í”Œ ìˆ˜: {total_samples:,}ê°œ\n")
                f.write(f"í´ë˜ìŠ¤ ìˆ˜: {len(imbalance_data)}ê°œ\n\n")
                
                f.write("í´ë˜ìŠ¤ë³„ ì„¸ë¶€ ì •ë³´:\n")
                f.write("-" * 50 + "\n")
                
                for d in imbalance_data:
                    f.write(f"í´ë˜ìŠ¤ {d['target']:2d}: {d['class_name']}\n")
                    f.write(f"  ìƒ˜í”Œ ìˆ˜: {d['count']:3d}ê°œ\n")
                    f.write(f"  ë¹„ìœ¨: {d['percentage']:5.1f}%\n")
                    f.write("\n")
            
            print(f"ğŸ“„ í´ë˜ìŠ¤ ì •ë³´ í…ìŠ¤íŠ¸ ì €ì¥: {self.output_dir / 'class_distribution.txt'}")
            
        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _calculate_class_weights(self, class_counts: pd.Series):
        """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        print(f"\nğŸ’¡ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì œì•ˆ:")
        
        # Balanced ê°€ì¤‘ì¹˜ ê³„ì‚°
        n_samples = class_counts.sum()
        n_classes = len(class_counts)
        balanced_weights = n_samples / (n_classes * class_counts)
        
        print(f"  ğŸ“‹ Balanced Class Weights:")
        for target, weight in balanced_weights.items():
            class_name = self.dataset_analyzer.class_mapping[target]
            print(f"    {target:2d}: {weight:.3f} - {class_name[:30]}")
        
        # ê°€ì¤‘ì¹˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
        weights_dict = balanced_weights.to_dict()
        with open(self.output_dir / 'class_weights.json', 'w') as f:
            json.dump(weights_dict, f, indent=2)
        
        print(f"  ğŸ’¾ ê°€ì¤‘ì¹˜ ì €ì¥: {self.output_dir / 'class_weights.json'}")
    
    def _analyze_train_test_differences(self):
        """Train/Test ë°ì´í„° ì°¨ì´ ë¶„ì„ (ëŒ€íšŒ í•µì‹¬!)"""
        print("=== ğŸ” 3. Train/Test ì°¨ì´ ë¶„ì„ (ëŒ€íšŒ í•µì‹¬!) ===")
        
        # ìƒ˜í”Œë§ (ì „ì²´ ë¶„ì„ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
        train_paths = self.dataset_analyzer.get_image_paths('train')
        test_paths = self.dataset_analyzer.get_image_paths('test')
        
        # ìƒ˜í”Œ í¬ê¸° ì„¤ì •
        train_sample_size = min(300, len(train_paths))
        test_sample_size = min(150, len(test_paths))
        
        print(f"ğŸ“Š ìƒ˜í”Œ ë¶„ì„ (Train: {train_sample_size}ê°œ, Test: {test_sample_size}ê°œ)")
        
        # ëœë¤ ìƒ˜í”Œë§
        train_sample = random.sample(train_paths, train_sample_size)
        test_sample = random.sample(test_paths, test_sample_size)
        
        # ì´ë¯¸ì§€ ë¶„ì„
        print("ğŸ”„ Train ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        train_metrics = self.dataset_analyzer.analyze_images_batch(train_sample)
        
        print("ğŸ”„ Test ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        test_metrics = self.dataset_analyzer.analyze_images_batch(test_sample)
        
        # ê²°ê³¼ ë¹„êµ
        self._compare_train_test_metrics(train_metrics, test_metrics)
        
        print()
    
    def _compare_train_test_metrics(self, train_metrics: List[ImageMetrics], test_metrics: List[ImageMetrics]):
        """Train/Test ë©”íŠ¸ë¦­ ë¹„êµ"""
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        train_df = pd.DataFrame([m.to_dict() for m in train_metrics])
        test_df = pd.DataFrame([m.to_dict() for m in test_metrics])
        
        train_df['dataset'] = 'Train'
        test_df['dataset'] = 'Test'
        combined_df = pd.concat([train_df, test_df], ignore_index=True)
        
        # í†µê³„ ë¹„êµ
        print("ğŸ“ˆ Train vs Test í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¹„êµ:")
        
        metrics_to_compare = ['brightness', 'contrast', 'sharpness', 'noise_level', 'rotation_angle']
        
        for metric in metrics_to_compare:
            train_values = train_df[metric]
            test_values = test_df[metric]
            
            # t-test ìˆ˜í–‰
            t_stat, p_value = stats.ttest_ind(train_values, test_values)
            
            print(f"\n  ğŸ“Š {metric.upper()}:")
            print(f"    Train: {train_values.mean():.2f} Â± {train_values.std():.2f}")
            print(f"    Test:  {test_values.mean():.2f} Â± {test_values.std():.2f}")
            print(f"    ì°¨ì´:   {test_values.mean() - train_values.mean():+.2f}")
            print(f"    p-value: {p_value:.4f} {'(ìœ ì˜í•¨)' if p_value < 0.05 else '(ìœ ì˜í•˜ì§€ ì•ŠìŒ)'}")
        
        # ì‹œê°í™”
        self._plot_train_test_comparison(combined_df)
        
        # ëŒ€íšŒ ì „ëµ ì¸ì‚¬ì´íŠ¸
        self._generate_train_test_insights(train_df, test_df)
    
    def _plot_train_test_comparison(self, combined_df: pd.DataFrame):
        """Train/Test ë¹„êµ ì‹œê°í™” (í•œê¸€ ì§€ì›)"""
        
        # í°íŠ¸ ì¬ì„¤ì •
        setup_korean_font()
        
        # ë©”íŠ¸ë¦­ë³„ ë¶„í¬ ë¹„êµ
        metrics = ['brightness', 'contrast', 'sharpness', 'noise_level', 'rotation_angle']
        metric_names_en = ['Brightness', 'Contrast', 'Sharpness', 'Noise Level', 'Rotation Angle']
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, (metric, name_en) in enumerate(zip(metrics, metric_names_en)):
            ax = axes[i]
            
            # íˆìŠ¤í† ê·¸ë¨
            train_data = combined_df[combined_df['dataset'] == 'Train'][metric]
            test_data = combined_df[combined_df['dataset'] == 'Test'][metric]
            
            ax.hist(train_data, bins=30, alpha=0.7, label='Train', color='blue', density=True)
            ax.hist(test_data, bins=30, alpha=0.7, label='Test', color='red', density=True)
            
            ax.set_xlabel(f'{name_en}', fontsize=11, fontweight='bold')
            ax.set_ylabel('Density', fontsize=11, fontweight='bold')
            ax.set_title(f'{name_en} Distribution Comparison', fontsize=12, fontweight='bold')
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        # ë§ˆì§€ë§‰ subplot ì œê±°
        axes[-1].remove()
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'train_test_comparison.png', 
                   dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"ğŸ“Š Train/Test ë¹„êµ ì°¨íŠ¸ ì €ì¥: {self.output_dir / 'train_test_comparison.png'}")
    
    def _generate_train_test_insights(self, train_df: pd.DataFrame, test_df: pd.DataFrame):
        """Train/Test ì°¨ì´ ê¸°ë°˜ ëŒ€íšŒ ì „ëµ ì¸ì‚¬ì´íŠ¸"""
        print(f"\nğŸ’¡ ëŒ€íšŒ ì „ëµ ì¸ì‚¬ì´íŠ¸:")
        
        # íšŒì „ ë¶„ì„
        train_rotation_std = train_df['rotation_angle'].std()
        test_rotation_std = test_df['rotation_angle'].std()
        
        if test_rotation_std > train_rotation_std * 1.5:
            print(f"  ğŸ”„ íšŒì „: Test ë°ì´í„°ì˜ íšŒì „ì´ ë” ë‹¤ì–‘í•¨ (std: {test_rotation_std:.1f} vs {train_rotation_std:.1f})")
            print(f"      â†’ RandomRotation(degrees=(-30, 30)) ì¦ê°• í•„ìˆ˜!")
        
        # ë…¸ì´ì¦ˆ ë¶„ì„
        train_noise_mean = train_df['noise_level'].mean()
        test_noise_mean = test_df['noise_level'].mean()
        
        if test_noise_mean > train_noise_mean * 1.2:
            print(f"  ğŸ”Š ë…¸ì´ì¦ˆ: Test ë°ì´í„°ê°€ ë” ë…¸ì´ì§€í•¨ ({test_noise_mean:.2f} vs {train_noise_mean:.2f})")
            print(f"      â†’ GaussianNoise, ISONoise ì¦ê°• ì¶”ê°€!")
        
        # ì„ ëª…ë„ ë¶„ì„
        train_sharp_mean = train_df['sharpness'].mean()
        test_sharp_mean = test_df['sharpness'].mean()
        
        if test_sharp_mean < train_sharp_mean * 0.8:
            print(f"  ğŸŒ«ï¸ ë¸”ëŸ¬: Test ë°ì´í„°ê°€ ë” íë¦¼ ({test_sharp_mean:.1f} vs {train_sharp_mean:.1f})")
            print(f"      â†’ MotionBlur, GaussianBlur ì¦ê°• ì¶”ê°€!")
        
        # ë°ê¸° ë¶„ì„
        train_bright_mean = train_df['brightness'].mean()
        test_bright_mean = test_df['brightness'].mean()
        
        if abs(test_bright_mean - train_bright_mean) > 10:
            print(f"  ğŸ’¡ ë°ê¸°: ì°¨ì´ ìˆìŒ ({test_bright_mean:.1f} vs {train_bright_mean:.1f})")
            print(f"      â†’ RandomBrightnessContrast ì¦ê°• í•„ìˆ˜!")
    
    def _detect_anomalous_images(self):
        """ì´ì§ˆì  ì´ë¯¸ì§€ íƒì§€ (ì°¨ëŸ‰ ëŒ€ì‹œë³´ë“œ, ë²ˆí˜¸íŒ ë“±)"""
        print("=== ğŸš¨ 4. ì´ì§ˆì  ì´ë¯¸ì§€ íƒì§€ ===")
        
        # í´ë˜ìŠ¤ë³„ íŠ¹ì„± ë¶„ì„
        train_df = self.dataset_analyzer.train_df
        class_mapping = self.dataset_analyzer.class_mapping
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í´ë˜ìŠ¤ë“¤ (ì°¨ëŸ‰ ê´€ë ¨)
        vehicle_classes = [2, 16]  # car_dashboard, vehicle_registration_plate
        
        print("ğŸš— ì°¨ëŸ‰ ê´€ë ¨ í´ë˜ìŠ¤ ë¶„ì„:")
        for class_id in vehicle_classes:
            class_name = class_mapping[class_id]
            count = len(train_df[train_df['target'] == class_id])
            print(f"  {class_id:2d}: {class_name} - {count}ê°œ")
        
        # ì°¨ëŸ‰ ê´€ë ¨ ì´ë¯¸ì§€ë“¤ì˜ íŠ¹ì„± ë¶„ì„
        vehicle_samples = []
        other_samples = []
        
        # ìƒ˜í”Œ ìˆ˜ì§‘ (ê° í´ë˜ìŠ¤ì—ì„œ ëª‡ ê°œì”©)
        for class_id in range(17):
            class_images = train_df[train_df['target'] == class_id]['ID'].tolist()
            sample_size = min(10, len(class_images))
            samples = random.sample(class_images, sample_size)
            
            for img_id in samples:
                img_path = self.dataset_analyzer.train_dir / img_id
                if class_id in vehicle_classes:
                    vehicle_samples.append(img_path)
                else:
                    other_samples.append(img_path)
        
        print(f"\nğŸ” ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„ ì¤‘... (ì°¨ëŸ‰: {len(vehicle_samples)}ê°œ, ê¸°íƒ€: {len(other_samples)}ê°œ)")
        
        # ì´ë¯¸ì§€ ë¶„ì„
        vehicle_metrics = self.dataset_analyzer.analyze_images_batch(vehicle_samples[:50])
        other_metrics = self.dataset_analyzer.analyze_images_batch(other_samples[:100])
        
        # íŠ¹ì„± ë¹„êµ
        self._compare_anomalous_vs_normal(vehicle_metrics, other_metrics)
        
        print()
    
    def _compare_anomalous_vs_normal(self, vehicle_metrics: List[ImageMetrics], other_metrics: List[ImageMetrics]):
        """ì´ì§ˆì  ì´ë¯¸ì§€ vs ì¼ë°˜ ë¬¸ì„œ ë¹„êµ"""
        
        if not vehicle_metrics or not other_metrics:
            print("âš ï¸ ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        print("ğŸ“Š ì°¨ëŸ‰ ê´€ë ¨ vs ì¼ë°˜ ë¬¸ì„œ íŠ¹ì„± ë¹„êµ:")
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        vehicle_df = pd.DataFrame([m.to_dict() for m in vehicle_metrics])
        other_df = pd.DataFrame([m.to_dict() for m in other_metrics])
        
        metrics = ['brightness', 'contrast', 'aspect_ratio', 'sharpness']
        
        for metric in metrics:
            vehicle_values = vehicle_df[metric]
            other_values = other_df[metric]
            
            print(f"\n  ğŸ“Š {metric.upper()}:")
            print(f"    ì°¨ëŸ‰:   {vehicle_values.mean():.2f} Â± {vehicle_values.std():.2f}")
            print(f"    ì¼ë°˜:   {other_values.mean():.2f} Â± {other_values.std():.2f}")
            print(f"    ì°¨ì´:   {vehicle_values.mean() - other_values.mean():+.2f}")
        
        # ì „ëµ ì œì•ˆ
        print(f"\nğŸ’¡ ì´ì§ˆì  ì´ë¯¸ì§€ ëŒ€ì‘ ì „ëµ:")
        
        # ì¢…íš¡ë¹„ ì°¨ì´ê°€ í° ê²½ìš°
        vehicle_ar_mean = vehicle_df['aspect_ratio'].mean()
        other_ar_mean = other_df['aspect_ratio'].mean()
        
        if abs(vehicle_ar_mean - other_ar_mean) > 0.3:
            print(f"  ğŸ“ ì¢…íš¡ë¹„ ì°¨ì´ í¼ â†’ Multi-scale training í•„ìš”")
            print(f"      â†’ 448x448, 512x512, 576x576 í•´ìƒë„ë¡œ í•™ìŠµ")
        
        # ë°ê¸° ì°¨ì´ê°€ í° ê²½ìš°  
        vehicle_bright_mean = vehicle_df['brightness'].mean()
        other_bright_mean = other_df['brightness'].mean()
        
        if abs(vehicle_bright_mean - other_bright_mean) > 15:
            print(f"  ğŸ’¡ ë°ê¸° ì°¨ì´ í¼ â†’ ê°•í•œ Color Augmentation í•„ìš”")
        
        print(f"  ğŸ¯ Binary Classifier ê³ ë ¤: ì°¨ëŸ‰ vs ë¬¸ì„œ ë¶„ë¥˜ í›„ ê°ê° ë‹¤ë¥¸ ëª¨ë¸ ì ìš©")
    
    def _analyze_image_quality(self):
        """ì´ë¯¸ì§€ í’ˆì§ˆ ìƒì„¸ ë¶„ì„"""
        print("=== ğŸ” 5. ì´ë¯¸ì§€ í’ˆì§ˆ ìƒì„¸ ë¶„ì„ ===")
        
        # ìƒ˜í”Œ ë¶„ì„ (ì‹œê°„ ì ˆì•½)
        train_paths = self.dataset_analyzer.get_image_paths('train')
        sample_paths = random.sample(train_paths, min(200, len(train_paths)))
        
        print(f"ğŸ”„ ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì¤‘... ({len(sample_paths)}ê°œ ìƒ˜í”Œ)")
        metrics = self.dataset_analyzer.analyze_images_batch(sample_paths)
        
        if not metrics:
            print("âš ï¸ ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame([m.to_dict() for m in metrics])
        
        # í’ˆì§ˆ í†µê³„
        print("ğŸ“Š ì´ë¯¸ì§€ í’ˆì§ˆ í†µê³„:")
        quality_metrics = ['brightness', 'contrast', 'sharpness', 'noise_level']
        
        for metric in quality_metrics:
            values = df[metric]
            print(f"  {metric.upper()}:")
            print(f"    í‰ê· : {values.mean():.2f}")
            print(f"    í‘œì¤€í¸ì°¨: {values.std():.2f}")
            print(f"    ë²”ìœ„: {values.min():.2f} ~ {values.max():.2f}")
        
        # í’ˆì§ˆ ë¶„í¬ ì‹œê°í™”
        self._plot_quality_distributions(df)
        
        # í’ˆì§ˆ ê¸°ë°˜ ì¦ê°• ì „ëµ
        self._suggest_quality_based_augmentation(df)
        
        print()
    
    def _plot_quality_distributions(self, df: pd.DataFrame):
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¶„í¬ ì‹œê°í™” (í•œê¸€ ì§€ì›)"""
        
        # í°íŠ¸ ì¬ì„¤ì •
        setup_korean_font()
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        quality_metrics = ['brightness', 'contrast', 'sharpness', 'noise_level']
        metric_names_en = ['Brightness', 'Contrast', 'Sharpness', 'Noise Level']
        colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightsalmon']
        
        for i, (metric, name_en) in enumerate(zip(quality_metrics, metric_names_en)):
            ax = axes[i]
            values = df[metric]
            
            # íˆìŠ¤í† ê·¸ë¨
            ax.hist(values, bins=30, alpha=0.7, color=colors[i], edgecolor='black')
            ax.axvline(values.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {values.mean():.1f}')
            ax.axvline(values.median(), color='blue', linestyle='--', linewidth=2, label=f'Median: {values.median():.1f}')
            
            ax.set_xlabel(f'{name_en}', fontsize=11, fontweight='bold')
            ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')
            ax.set_title(f'{name_en} Distribution', fontsize=12, fontweight='bold')
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'quality_distributions.png', 
                   dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"ğŸ“Š í’ˆì§ˆ ë¶„í¬ ì°¨íŠ¸ ì €ì¥: {self.output_dir / 'quality_distributions.png'}")
    
    def _suggest_quality_based_augmentation(self, df: pd.DataFrame):
        """í’ˆì§ˆ ê¸°ë°˜ ì¦ê°• ì „ëµ ì œì•ˆ"""
        print(f"\nğŸ’¡ í’ˆì§ˆ ê¸°ë°˜ ì¦ê°• ì „ëµ:")
        
        # ë°ê¸° ë¶„ì„
        brightness_std = df['brightness'].std()
        if brightness_std < 20:
            print(f"  ğŸ’¡ ë°ê¸° ë³€í™” ë¶€ì¡± â†’ RandomBrightnessContrast(brightness_limit=0.3)")
        
        # ëŒ€ë¹„ ë¶„ì„
        contrast_std = df['contrast'].std()
        if contrast_std < 15:
            print(f"  ğŸŒˆ ëŒ€ë¹„ ë³€í™” ë¶€ì¡± â†’ RandomBrightnessContrast(contrast_limit=0.3)")
        
        # ì„ ëª…ë„ ë¶„ì„
        sharpness_mean = df['sharpness'].mean()
        if sharpness_mean > 1000:
            print(f"  ğŸ” ì´ë¯¸ì§€ ì„ ëª…í•¨ â†’ Blur ì¦ê°•ìœ¼ë¡œ ì¼ë°˜í™” ê°œì„ ")
            print(f"      â†’ MotionBlur(blur_limit=3), GaussianBlur(blur_limit=3)")
        
        # ë…¸ì´ì¦ˆ ë¶„ì„
        noise_mean = df['noise_level'].mean()
        if noise_mean < 5:
            print(f"  ğŸ”‡ ë…¸ì´ì¦ˆ ë¶€ì¡± â†’ GaussianNoise(var_limit=(10, 50))")
    
    def _analyze_image_dimensions(self):
        """ì´ë¯¸ì§€ í¬ê¸°/ì¢…íš¡ë¹„ ë¶„ì„"""
        print("=== ğŸ“ 6. ì´ë¯¸ì§€ í¬ê¸°/ì¢…íš¡ë¹„ ë¶„ì„ ===")
        
        # ìƒ˜í”Œ ë¶„ì„
        train_paths = self.dataset_analyzer.get_image_paths('train')
        test_paths = self.dataset_analyzer.get_image_paths('test')
        
        train_sample = random.sample(train_paths, min(200, len(train_paths)))
        test_sample = random.sample(test_paths, min(100, len(test_paths)))
        
        print(f"ğŸ“Š í¬ê¸° ë¶„ì„ ì¤‘... (Train: {len(train_sample)}ê°œ, Test: {len(test_sample)}ê°œ)")
        
        # ì´ë¯¸ì§€ ë¶„ì„
        train_metrics = self.dataset_analyzer.analyze_images_batch(train_sample)
        test_metrics = self.dataset_analyzer.analyze_images_batch(test_sample)
        
        # í¬ê¸° í†µê³„
        self._analyze_dimension_statistics(train_metrics, test_metrics)
        
        # ìµœì  resize ì „ëµ ì œì•ˆ
        self._suggest_resize_strategy(train_metrics, test_metrics)
        
        print()
    
    def _analyze_dimension_statistics(self, train_metrics: List[ImageMetrics], test_metrics: List[ImageMetrics]):
        """í¬ê¸° í†µê³„ ë¶„ì„"""
        
        if not train_metrics or not test_metrics:
            print("âš ï¸ ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        train_df = pd.DataFrame([m.to_dict() for m in train_metrics])
        test_df = pd.DataFrame([m.to_dict() for m in test_metrics])
        
        print("ğŸ“Š ì´ë¯¸ì§€ í¬ê¸° í†µê³„:")
        
        # í¬ê¸° í†µê³„
        for dataset_name, df in [("Train", train_df), ("Test", test_df)]:
            print(f"\n  {dataset_name} ë°ì´í„°:")
            print(f"    ë„ˆë¹„: {df['width'].mean():.0f} Â± {df['width'].std():.0f} (ë²”ìœ„: {df['width'].min()}-{df['width'].max()})")
            print(f"    ë†’ì´: {df['height'].mean():.0f} Â± {df['height'].std():.0f} (ë²”ìœ„: {df['height'].min()}-{df['height'].max()})")
            print(f"    ì¢…íš¡ë¹„: {df['aspect_ratio'].mean():.2f} Â± {df['aspect_ratio'].std():.2f}")
            print(f"    íŒŒì¼í¬ê¸°: {df['file_size_kb'].mean():.0f}KB Â± {df['file_size_kb'].std():.0f}KB")
        
        # í¬ê¸° ë¶„í¬ ì‹œê°í™”
        self._plot_dimension_distributions(train_df, test_df)
    
    def _plot_dimension_distributions(self, train_df: pd.DataFrame, test_df: pd.DataFrame):
        """í¬ê¸° ë¶„í¬ ì‹œê°í™” (í•œê¸€ ì§€ì›)"""
        
        # í°íŠ¸ ì¬ì„¤ì •
        setup_korean_font()
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ë„ˆë¹„ ë¶„í¬
        axes[0,0].hist(train_df['width'], bins=30, alpha=0.7, label='Train', color='blue', density=True)
        axes[0,0].hist(test_df['width'], bins=30, alpha=0.7, label='Test', color='red', density=True)
        axes[0,0].set_xlabel('Width (pixels)', fontsize=11, fontweight='bold')
        axes[0,0].set_ylabel('Density', fontsize=11, fontweight='bold')
        axes[0,0].set_title('Width Distribution', fontsize=12, fontweight='bold')
        axes[0,0].legend(fontsize=10)
        axes[0,0].grid(True, alpha=0.3)
        
        # ë†’ì´ ë¶„í¬
        axes[0,1].hist(train_df['height'], bins=30, alpha=0.7, label='Train', color='blue', density=True)
        axes[0,1].hist(test_df['height'], bins=30, alpha=0.7, label='Test', color='red', density=True)
        axes[0,1].set_xlabel('Height (pixels)', fontsize=11, fontweight='bold')
        axes[0,1].set_ylabel('Density', fontsize=11, fontweight='bold')
        axes[0,1].set_title('Height Distribution', fontsize=12, fontweight='bold')
        axes[0,1].legend(fontsize=10)
        axes[0,1].grid(True, alpha=0.3)
        
        # ì¢…íš¡ë¹„ ë¶„í¬
        axes[1,0].hist(train_df['aspect_ratio'], bins=30, alpha=0.7, label='Train', color='blue', density=True)
        axes[1,0].hist(test_df['aspect_ratio'], bins=30, alpha=0.7, label='Test', color='red', density=True)
        axes[1,0].set_xlabel('Aspect Ratio (W/H)', fontsize=11, fontweight='bold')
        axes[1,0].set_ylabel('Density', fontsize=11, fontweight='bold')
        axes[1,0].set_title('Aspect Ratio Distribution', fontsize=12, fontweight='bold')
        axes[1,0].legend(fontsize=10)
        axes[1,0].grid(True, alpha=0.3)
        
        # í¬ê¸° ì‚°ì ë„
        axes[1,1].scatter(train_df['width'], train_df['height'], alpha=0.6, label='Train', color='blue', s=20)
        axes[1,1].scatter(test_df['width'], test_df['height'], alpha=0.6, label='Test', color='red', s=20)
        axes[1,1].set_xlabel('Width (pixels)', fontsize=11, fontweight='bold')
        axes[1,1].set_ylabel('Height (pixels)', fontsize=11, fontweight='bold')
        axes[1,1].set_title('Width vs Height', fontsize=12, fontweight='bold')
        axes[1,1].legend(fontsize=10)
        axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'dimension_distributions.png', 
                   dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"ğŸ“Š í¬ê¸° ë¶„í¬ ì°¨íŠ¸ ì €ì¥: {self.output_dir / 'dimension_distributions.png'}")
    
    def _suggest_resize_strategy(self, train_metrics: List[ImageMetrics], test_metrics: List[ImageMetrics]):
        """ìµœì  resize ì „ëµ ì œì•ˆ"""
        
        if not train_metrics or not test_metrics:
            return
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        train_df = pd.DataFrame([m.to_dict() for m in train_metrics])
        test_df = pd.DataFrame([m.to_dict() for m in test_metrics])
        
        print(f"\nğŸ’¡ Resize ì „ëµ ì œì•ˆ:")
        
        # ì¢…íš¡ë¹„ ë¶„ì„
        train_ar_std = train_df['aspect_ratio'].std()
        test_ar_std = test_df['aspect_ratio'].std()
        combined_ar_std = pd.concat([train_df['aspect_ratio'], test_df['aspect_ratio']]).std()
        
        if combined_ar_std > 0.5:
            print(f"  ğŸ“ ì¢…íš¡ë¹„ ë‹¤ì–‘í•¨ (std: {combined_ar_std:.2f})")
            print(f"      â†’ Aspect Ratio ìœ ì§€í•˜ëŠ” Resize ì¶”ì²œ")
            print(f"      â†’ Letterbox Padding ë˜ëŠ” Adaptive Resize ì‚¬ìš©")
        else:
            print(f"  ğŸ“ ì¢…íš¡ë¹„ ì¼ì •í•¨ (std: {combined_ar_std:.2f})")
            print(f"      â†’ Square Resize (448x448, 512x512) ê°€ëŠ¥")
        
        # ìµœì  í¬ê¸° ì œì•ˆ
        train_widths = train_df['width']
        train_heights = train_df['height']
        
        # 95% ë¶„ìœ„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìµœì  í¬ê¸° ê³„ì‚°
        width_95 = np.percentile(train_widths, 95)
        height_95 = np.percentile(train_heights, 95)
        
        # 32ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤ (CNN íš¨ìœ¨ì„±)
        optimal_size = max(width_95, height_95)
        optimal_size = int(np.ceil(optimal_size / 32) * 32)
        
        print(f"  ğŸ¯ ê¶Œì¥ ì´ë¯¸ì§€ í¬ê¸°: {optimal_size}x{optimal_size}")
        print(f"      â†’ 95% ì´ë¯¸ì§€ê°€ ì†ì‹¤ ì—†ì´ í¬í•¨ë¨")
        
        # Multi-scale ì „ëµ
        scales = [optimal_size - 64, optimal_size, optimal_size + 64]
        print(f"  ğŸ”„ Multi-scale í•™ìŠµ ê¶Œì¥: {scales}")
    
    def _generate_competition_strategy(self):
        """ìµœì¢… ëŒ€íšŒ ì „ëµ ìƒì„±"""
        print("=== ğŸ† 7. ìµœì¢… ëŒ€íšŒ ì „ëµ ì œì•ˆ ===")
        
        strategy = {
            "augmentation": self._get_augmentation_strategy(),
            "model_architecture": self._get_model_strategy(),
            "training": self._get_training_strategy(),
            "ensemble": self._get_ensemble_strategy()
        }
        
        # ì „ëµ ì¶œë ¥
        for category, recommendations in strategy.items():
            print(f"\nğŸ“‹ {category.upper()}:")
            for rec in recommendations:
                print(f"  â€¢ {rec}")
        
        # ì „ëµì„ JSONìœ¼ë¡œ ì €ì¥
        with open(self.output_dir / 'competition_strategy.json', 'w', encoding='utf-8') as f:
            json.dump(strategy, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ì „ëµ ì €ì¥: {self.output_dir / 'competition_strategy.json'}")
        
        # ì½”ë“œ ì˜ˆì‹œ ìƒì„±
        self._generate_augmentation_code()
        
        print()
    
    def _get_augmentation_strategy(self) -> List[str]:
        """ì¦ê°• ì „ëµ ì œì•ˆ"""
        return [
            "RandomRotation(degrees=(-30, 30)) - Test ë°ì´í„° íšŒì „ ëŒ€ì‘",
            "RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3)",
            "GaussianNoise(var_limit=(10, 50)) - Test ë…¸ì´ì¦ˆ ëŒ€ì‘",
            "MotionBlur(blur_limit=3) + GaussianBlur(blur_limit=3)",
            "RandomPerspective(distortion_scale=0.1) - ë¬¸ì„œ ì™œê³¡ ì‹œë®¬ë ˆì´ì…˜",
            "Cutout(num_holes=1, max_h_size=32, max_w_size=32) - ë¶€ë¶„ ê°€ë¦¼ ëŒ€ì‘",
            "MixUp(alpha=0.2) - í´ë˜ìŠ¤ ë¶ˆê· í˜• ì™„í™”",
            "CutMix(alpha=1.0) - ì†Œìˆ˜ í´ë˜ìŠ¤ ì¦ê°•"
        ]
    
    def _get_model_strategy(self) -> List[str]:
        """ëª¨ë¸ ì „ëµ ì œì•ˆ"""
        return [
            "EfficientNetV2-S/M - ë¬¸ì„œ ë¶„ë¥˜ì— ìµœì í™”ëœ ì•„í‚¤í…ì²˜",
            "ConvNeXt-Tiny/Small - ìµœì‹  CNN ì•„í‚¤í…ì²˜",
            "Swin Transformer-Tiny - Vision Transformer ì˜µì…˜",
            "Multi-scale Input (448x448, 512x512, 576x576)",
            "Focal Loss - í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘",
            "Label Smoothing (0.1) - ê³¼ì í•© ë°©ì§€",
            "Dropout ê°•í™” (0.3-0.5) - ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ"
        ]
    
    def _get_training_strategy(self) -> List[str]:
        """í›ˆë ¨ ì „ëµ ì œì•ˆ"""
        return [
            "Stratified 5-Fold Cross Validation",
            "AdamW Optimizer (lr=1e-4, weight_decay=1e-2)",
            "CosineAnnealingWarmRestarts ìŠ¤ì¼€ì¤„ëŸ¬",
            "Early Stopping (patience=5, monitor='val_f1')",
            "Gradient Clipping (max_norm=1.0)",
            "Mixed Precision Training (AMP)",
            "Class Weights ì ìš© - ë¶ˆê· í˜• ëŒ€ì‘",
            "Pseudo Labeling (confidence > 0.9) - í›„ë°˜ë¶€ ì ìš©"
        ]
    
    def _get_ensemble_strategy(self) -> List[str]:
        """ì•™ìƒë¸” ì „ëµ ì œì•ˆ"""
        return [
            "5-Fold ì•™ìƒë¸” (ê° foldë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸)",
            "Multi-Architecture ì•™ìƒë¸” (EfficientNet + ConvNeXt + Swin)",
            "TTA (Test Time Augmentation): íšŒì „, í”Œë¦½, ìŠ¤ì¼€ì¼ë§",
            "Soft Voting - í™•ë¥  í‰ê· ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡",
            "Confidence-based Weighted Voting",
            "Private LB ì•ˆì •ì„±ì„ ìœ„í•œ Conservative ì•™ìƒë¸”"
        ]
    
    def _generate_augmentation_code(self):
        """ì¦ê°• ì½”ë“œ ì˜ˆì‹œ ìƒì„±"""
        
        augmentation_code = '''
import albumentations as A
from albumentations.pytorch import ToTensorV2

def get_train_transforms(image_size=512):
    """
    ëŒ€íšŒ ì „ëµ ê¸°ë°˜ Train Augmentation
    Train/Test ì°¨ì´ë¥¼ ë°˜ì˜í•œ ê°•í™”ëœ ì¦ê°•
    """
    return A.Compose([
        # ê¸°ë³¸ Resize
        A.Resize(image_size, image_size),
        
        # íšŒì „ - Test ë°ì´í„° íšŒì „ ëŒ€ì‘ (í•µì‹¬!)
        A.RandomRotate90(p=0.3),
        A.Rotate(limit=30, p=0.7, border_mode=cv2.BORDER_CONSTANT, value=255),
        
        # ë°ê¸°/ëŒ€ë¹„ - Train/Test ì°¨ì´ ëŒ€ì‘
        A.RandomBrightnessContrast(
            brightness_limit=0.3, 
            contrast_limit=0.3, 
            p=0.8
        ),
        
        # ë…¸ì´ì¦ˆ - Test ë°ì´í„° ë…¸ì´ì¦ˆ ëŒ€ì‘
        A.OneOf([
            A.GaussianNoise(var_limit=(10, 50)),
            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5)),
        ], p=0.5),
        
        # ë¸”ëŸ¬ - Test ë°ì´í„° ë¸”ëŸ¬ ëŒ€ì‘
        A.OneOf([
            A.MotionBlur(blur_limit=3),
            A.GaussianBlur(blur_limit=3),
        ], p=0.3),
        
        # ê¸°í•˜í•™ì  ë³€í˜• - ë¬¸ì„œ ìŠ¤ìº” ì‹œë®¬ë ˆì´ì…˜
        A.RandomPerspective(distortion_scale=0.1, p=0.3),
        A.ShiftScaleRotate(
            shift_limit=0.1, 
            scale_limit=0.1, 
            rotate_limit=0, 
            p=0.3
        ),
        
        # ë¶€ë¶„ ê°€ë¦¼ - ì‹¤ì œ ë¬¸ì„œ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
        A.Cutout(
            num_holes=1, 
            max_h_size=32, 
            max_w_size=32, 
            fill_value=255,
            p=0.3
        ),
        
        # ìƒ‰ìƒ ë³€í˜• - ìŠ¤ìº” í’ˆì§ˆ ë‹¤ì–‘í™”
        A.OneOf([
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10),
            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        ], p=0.3),
        
        # Normalization & Tensor ë³€í™˜
        A.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        ToTensorV2()
    ])

def get_valid_transforms(image_size=512):
    """Validationìš© ê¸°ë³¸ ë³€í™˜"""
    return A.Compose([
        A.Resize(image_size, image_size),
        A.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        ToTensorV2()
    ])

def get_tta_transforms(image_size=512):
    """Test Time Augmentationìš© ë³€í™˜ë“¤"""
    transforms = []
    
    # ê¸°ë³¸
    transforms.append(A.Compose([
        A.Resize(image_size, image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ]))
    
    # ìˆ˜í‰ í”Œë¦½
    transforms.append(A.Compose([
        A.Resize(image_size, image_size),
        A.HorizontalFlip(p=1.0),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ]))
    
    # ì‘ì€ íšŒì „ë“¤
    for angle in [-5, 5]:
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.Rotate(limit=[angle, angle], border_mode=cv2.BORDER_CONSTANT, value=255, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]))
    
    return transforms

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (EDA ê²°ê³¼ ê¸°ë°˜)
CLASS_WEIGHTS = {
    # EDA ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ìë™ ìƒì„±ë¨
    # ì˜ˆì‹œ: {0: 1.2, 1: 0.8, 2: 1.5, ...}
}
'''
        
        # ì½”ë“œ ì €ì¥
        with open(self.output_dir / 'augmentation_strategy.py', 'w', encoding='utf-8') as f:
            f.write(augmentation_code)
        
        print(f"ğŸ’» ì¦ê°• ì½”ë“œ ì €ì¥: {self.output_dir / 'augmentation_strategy.py'}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    data_root = Path("/home/james/doc-classification/computervisioncompetition-cv3/data")
    
    if not data_root.exists():
        print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_root}")
        return
    
    try:
        # EDA ì‹¤í–‰
        eda = CompetitionEDA(data_root)
        eda.run_complete_analysis()
        
        print("\nğŸ‰ Competition EDA ì™„ë£Œ!")
        print("ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤:")
        print(f"  â€¢ í´ë˜ìŠ¤ ë¶„í¬: {eda.output_dir / 'class_distribution.png'}")
        print(f"  â€¢ Train/Test ë¹„êµ: {eda.output_dir / 'train_test_comparison.png'}")
        print(f"  â€¢ í’ˆì§ˆ ë¶„í¬: {eda.output_dir / 'quality_distributions.png'}")
        print(f"  â€¢ í¬ê¸° ë¶„í¬: {eda.output_dir / 'dimension_distributions.png'}")
        print(f"  â€¢ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {eda.output_dir / 'class_weights.json'}")
        print(f"  â€¢ ëŒ€íšŒ ì „ëµ: {eda.output_dir / 'competition_strategy.json'}")
        print(f"  â€¢ ì¦ê°• ì½”ë“œ: {eda.output_dir / 'augmentation_strategy.py'}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
