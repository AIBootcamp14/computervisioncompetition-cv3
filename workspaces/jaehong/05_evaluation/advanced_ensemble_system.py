"""
ğŸ­ Advanced Ensemble System
í´ë¦° ì½”ë“œì™€ í´ë¦° ì•„í‚¤í…ì²˜ë¥¼ ì ìš©í•œ ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ

Features:
- ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” (Voting, Averaging, Stacking)
- ê³ ê¸‰ TTA (Test Time Augmentation) ì „ëµ
- ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
- ë¶ˆí™•ì‹¤ì„± ì¶”ì •
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ êµ¬í˜„
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
from abc import ABC, abstractmethod
import warnings
from sklearn.metrics import f1_score, accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
import pickle

warnings.filterwarnings('ignore')


class BaseEnsemble(ABC):
    """
    ì•™ìƒë¸”ì˜ ì¶”ìƒ ê¸°ë°˜ í´ë˜ìŠ¤
    í´ë¦° ì•„í‚¤í…ì²˜ ì›ì¹™: ì˜ì¡´ì„± ì—­ì „
    """
    
    def __init__(self, models: List[nn.Module], device: str = "cuda"):
        self.models = models
        self.device = device
        self.model_weights = None
        
        # ëª¨ë¸ë“¤ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        for model in self.models:
            model.eval()
            model.to(device)
    
    @abstractmethod
    def predict(self, data_loader) -> Tuple[np.ndarray, np.ndarray]:
        """ì˜ˆì¸¡ ì¶”ìƒ ë©”ì„œë“œ"""
        pass
    
    @abstractmethod
    def predict_proba(self, data_loader) -> np.ndarray:
        """í™•ë¥  ì˜ˆì¸¡ ì¶”ìƒ ë©”ì„œë“œ"""
        pass


class VotingEnsemble(BaseEnsemble):
    """
    íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸”
    ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ íˆ¬í‘œë¡œ ê²°í•©
    """
    
    def __init__(
        self, 
        models: List[nn.Module], 
        weights: Optional[List[float]] = None,
        device: str = "cuda"
    ):
        super().__init__(models, device)
        self.weights = weights or [1.0] * len(models)
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.weights)
        self.weights = [w / total_weight for w in self.weights]
        
        print(f"ğŸ—³ï¸ íˆ¬í‘œ ì•™ìƒë¸” ì´ˆê¸°í™”: {len(models)}ê°œ ëª¨ë¸")
        print(f"   ê°€ì¤‘ì¹˜: {[f'{w:.3f}' for w in self.weights]}")
    
    def predict(self, data_loader) -> Tuple[np.ndarray, np.ndarray]:
        """íˆ¬í‘œ ê¸°ë°˜ ì˜ˆì¸¡"""
        all_predictions = []
        all_probabilities = []
        
        print(f"ğŸ”® íˆ¬í‘œ ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(data_loader):
                images = batch['image'].to(self.device)
                batch_predictions = []
                batch_probabilities = []
                
                # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ìˆ˜ì§‘
                for model_idx, model in enumerate(self.models):
                    outputs = model(images)
                    probs = F.softmax(outputs, dim=1)
                    
                    batch_predictions.append(outputs.cpu().numpy())
                    batch_probabilities.append(probs.cpu().numpy())
                
                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ê²°í•©
                weighted_probs = np.zeros_like(batch_probabilities[0])
                for i, (probs, weight) in enumerate(zip(batch_probabilities, self.weights)):
                    weighted_probs += probs * weight
                
                predictions = np.argmax(weighted_probs, axis=1)
                
                all_predictions.extend(predictions)
                all_probabilities.append(weighted_probs)
                
                if batch_idx % 50 == 0:
                    print(f"   ì§„í–‰ë¥ : {batch_idx+1}/{len(data_loader)} ë°°ì¹˜")
        
        final_probabilities = np.vstack(all_probabilities)
        
        print(f"âœ… íˆ¬í‘œ ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ!")
        return np.array(all_predictions), final_probabilities
    
    def predict_proba(self, data_loader) -> np.ndarray:
        """í™•ë¥  ì˜ˆì¸¡"""
        _, probabilities = self.predict(data_loader)
        return probabilities


class StackingEnsemble(BaseEnsemble):
    """
    ìŠ¤íƒœí‚¹ ì•™ìƒë¸”
    ë©”íƒ€ ëŸ¬ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ì„ ê²°í•©
    """
    
    def __init__(
        self, 
        models: List[nn.Module], 
        meta_learner=None,
        device: str = "cuda"
    ):
        super().__init__(models, device)
        self.meta_learner = meta_learner or LogisticRegression(
            random_state=42, 
            max_iter=1000,
            multi_class='ovr'
        )
        self.is_fitted = False
        
        print(f"ğŸ—ï¸ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì´ˆê¸°í™”: {len(models)}ê°œ ëª¨ë¸")
        print(f"   ë©”íƒ€ ëŸ¬ë„ˆ: {type(self.meta_learner).__name__}")
    
    def fit_meta_learner(self, val_loader, val_targets: np.ndarray):
        """
        ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨
        ê²€ì¦ ë°ì´í„°ë¡œ ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìƒì„±í•˜ê³  ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨
        """
        print(f"ğŸ“ ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨ ì¤‘...")
        
        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ìˆ˜ì§‘
        meta_features = []
        
        with torch.no_grad():
            for batch in val_loader:
                images = batch['image'].to(self.device)
                batch_meta_features = []
                
                for model in self.models:
                    outputs = model(images)
                    probs = F.softmax(outputs, dim=1)
                    batch_meta_features.append(probs.cpu().numpy())
                
                # ëª¨ë¸ë³„ ì˜ˆì¸¡ì„ ì—°ê²°í•˜ì—¬ ë©”íƒ€ íŠ¹ì„± ìƒì„±
                batch_meta = np.concatenate(batch_meta_features, axis=1)
                meta_features.append(batch_meta)
        
        X_meta = np.vstack(meta_features)
        
        # ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨
        self.meta_learner.fit(X_meta, val_targets)
        self.is_fitted = True
        
        # ì„±ëŠ¥ ê²€ì¦
        meta_predictions = self.meta_learner.predict(X_meta)
        meta_accuracy = accuracy_score(val_targets, meta_predictions)
        meta_f1 = f1_score(val_targets, meta_predictions, average='macro')
        
        print(f"âœ… ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨ ì™„ë£Œ!")
        print(f"   ë©”íƒ€ ëŸ¬ë„ˆ ì •í™•ë„: {meta_accuracy:.4f}")
        print(f"   ë©”íƒ€ ëŸ¬ë„ˆ F1: {meta_f1:.4f}")
    
    def predict(self, data_loader) -> Tuple[np.ndarray, np.ndarray]:
        """ìŠ¤íƒœí‚¹ ê¸°ë°˜ ì˜ˆì¸¡"""
        if not self.is_fitted:
            raise ValueError("ë©”íƒ€ ëŸ¬ë„ˆê°€ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit_meta_learner()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        print(f"ğŸ”® ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...")
        
        meta_features = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(data_loader):
                images = batch['image'].to(self.device)
                batch_meta_features = []
                
                for model in self.models:
                    outputs = model(images)
                    probs = F.softmax(outputs, dim=1)
                    batch_meta_features.append(probs.cpu().numpy())
                
                batch_meta = np.concatenate(batch_meta_features, axis=1)
                meta_features.append(batch_meta)
                
                if batch_idx % 50 == 0:
                    print(f"   ì§„í–‰ë¥ : {batch_idx+1}/{len(data_loader)} ë°°ì¹˜")
        
        X_meta = np.vstack(meta_features)
        
        # ë©”íƒ€ ëŸ¬ë„ˆë¡œ ìµœì¢… ì˜ˆì¸¡
        predictions = self.meta_learner.predict(X_meta)
        probabilities = self.meta_learner.predict_proba(X_meta)
        
        print(f"âœ… ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ!")
        return predictions, probabilities
    
    def predict_proba(self, data_loader) -> np.ndarray:
        """í™•ë¥  ì˜ˆì¸¡"""
        _, probabilities = self.predict(data_loader)
        return probabilities


class AdvancedTTAEnsemble:
    """
    ê³ ê¸‰ TTA (Test Time Augmentation) ì•™ìƒë¸”
    ë‹¤ì–‘í•œ ì¦ê°•ê³¼ ëª¨ë¸ì„ ê²°í•©
    """
    
    def __init__(
        self, 
        model: nn.Module, 
        tta_transforms: List,
        tta_weights: Optional[List[float]] = None,
        device: str = "cuda"
    ):
        self.model = model.to(device).eval()
        self.tta_transforms = tta_transforms
        self.device = device
        
        # TTA ê°€ì¤‘ì¹˜ ì„¤ì •
        if tta_weights is None:
            self.tta_weights = [1.0] * len(tta_transforms)
        else:
            self.tta_weights = tta_weights
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.tta_weights)
        self.tta_weights = [w / total_weight for w in self.tta_weights]
        
        print(f"ğŸ”„ ê³ ê¸‰ TTA ì•™ìƒë¸” ì´ˆê¸°í™”:")
        print(f"   TTA ë³€í™˜ ìˆ˜: {len(tta_transforms)}")
        print(f"   TTA ê°€ì¤‘ì¹˜: {[f'{w:.3f}' for w in self.tta_weights]}")
    
    def predict_with_tta(
        self, 
        image_paths: List[str], 
        image_size: int = 512,
        batch_size: int = 16
    ) -> Tuple[np.ndarray, np.ndarray, Dict[str, float]]:
        """
        TTAë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡
        ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì—¬ëŸ¬ ì¦ê°•ì„ ì ìš©í•˜ê³  ê²°ê³¼ë¥¼ í‰ê· 
        """
        print(f"ğŸ”® ê³ ê¸‰ TTA ì˜ˆì¸¡ ì¤‘... ({len(image_paths)}ê°œ ì´ë¯¸ì§€)")
        
        all_predictions = []
        all_probabilities = []
        confidence_scores = []
        
        # ì´ë¯¸ì§€ë³„ TTA ì˜ˆì¸¡
        for img_idx, img_path in enumerate(image_paths):
            tta_probs = []
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            import cv2
            image = cv2.imread(img_path)
            if image is None:
                # ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                image = np.ones((image_size, image_size, 3), dtype=np.uint8) * 128
            else:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ê° TTA ë³€í™˜ ì ìš©
            with torch.no_grad():
                for transform_idx, (transform, weight) in enumerate(zip(self.tta_transforms, self.tta_weights)):
                    # ë³€í™˜ ì ìš©
                    augmented = transform(image=image)
                    tensor_image = augmented['image'].unsqueeze(0).to(self.device)
                    
                    # ì˜ˆì¸¡
                    outputs = self.model(tensor_image)
                    probs = F.softmax(outputs, dim=1).cpu().numpy()[0]
                    
                    tta_probs.append(probs * weight)
            
            # TTA ê²°ê³¼ í‰ê· 
            final_probs = np.sum(tta_probs, axis=0)
            prediction = np.argmax(final_probs)
            confidence = np.max(final_probs)
            
            all_predictions.append(prediction)
            all_probabilities.append(final_probs)
            confidence_scores.append(confidence)
            
            if (img_idx + 1) % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {img_idx+1}/{len(image_paths)} ì´ë¯¸ì§€")
        
        # í†µê³„ ê³„ì‚°
        stats = {
            'mean_confidence': np.mean(confidence_scores),
            'std_confidence': np.std(confidence_scores),
            'min_confidence': np.min(confidence_scores),
            'max_confidence': np.max(confidence_scores),
            'high_confidence_ratio': np.mean(np.array(confidence_scores) > 0.8)
        }
        
        print(f"âœ… ê³ ê¸‰ TTA ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence']:.4f}")
        print(f"   ë†’ì€ ì‹ ë¢°ë„ ë¹„ìœ¨: {stats['high_confidence_ratio']:.2%}")
        
        return (
            np.array(all_predictions),
            np.array(all_probabilities),
            stats
        )


class EnsembleManager:
    """
    ì•™ìƒë¸” ê´€ë¦¬ì
    ë‹¤ì–‘í•œ ì•™ìƒë¸” ì „ëµì„ í†µí•© ê´€ë¦¬
    """
    
    def __init__(self, workspace_root: str):
        self.workspace_root = Path(workspace_root)
        self.models = {}
        self.ensembles = {}
        
        print(f"ğŸ­ ì•™ìƒë¸” ê´€ë¦¬ì ì´ˆê¸°í™”")
        print(f"   ì›Œí¬ìŠ¤í˜ì´ìŠ¤: {workspace_root}")
    
    def load_model(
        self, 
        model_name: str, 
        model_path: str, 
        model_config: Dict[str, Any],
        device: str = "cuda"
    ) -> nn.Module:
        """
        ëª¨ë¸ ë¡œë“œ ë° ë“±ë¡
        """
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¥¸ ë™ì  ì„í¬íŠ¸
        try:
            from ..03_modeling.improved_model_factory import ImprovedModelFactory
            
            model = ImprovedModelFactory.create_model(
                architecture=model_config.get('architecture', 'efficientnet_b3'),
                num_classes=model_config.get('num_classes', 17),
                pretrained=False,  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ
                **model_config
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=device, weights_only=False)
            
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model = model.to(device).eval()
            self.models[model_name] = model
            
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            return model
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name}, ì˜¤ë¥˜: {e}")
            return None
    
    def create_voting_ensemble(
        self, 
        model_names: List[str], 
        weights: Optional[List[float]] = None,
        ensemble_name: str = "voting_ensemble"
    ) -> VotingEnsemble:
        """íˆ¬í‘œ ì•™ìƒë¸” ìƒì„±"""
        models = [self.models[name] for name in model_names if name in self.models]
        
        if len(models) == 0:
            raise ValueError("ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        ensemble = VotingEnsemble(models, weights)
        self.ensembles[ensemble_name] = ensemble
        
        return ensemble
    
    def create_stacking_ensemble(
        self,
        model_names: List[str],
        meta_learner=None,
        ensemble_name: str = "stacking_ensemble"
    ) -> StackingEnsemble:
        """ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ìƒì„±"""
        models = [self.models[name] for name in model_names if name in self.models]
        
        if len(models) == 0:
            raise ValueError("ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        ensemble = StackingEnsemble(models, meta_learner)
        self.ensembles[ensemble_name] = ensemble
        
        return ensemble
    
    def create_tta_ensemble(
        self,
        model_name: str,
        tta_transforms: List,
        tta_weights: Optional[List[float]] = None,
        ensemble_name: str = "tta_ensemble"
    ) -> AdvancedTTAEnsemble:
        """TTA ì•™ìƒë¸” ìƒì„±"""
        if model_name not in self.models:
            raise ValueError(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_name}")
        
        ensemble = AdvancedTTAEnsemble(
            self.models[model_name],
            tta_transforms,
            tta_weights
        )
        self.ensembles[ensemble_name] = ensemble
        
        return ensemble
    
    def evaluate_ensemble(
        self,
        ensemble_name: str,
        val_loader,
        val_targets: np.ndarray
    ) -> Dict[str, float]:
        """ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€"""
        if ensemble_name not in self.ensembles:
            raise ValueError(f"ì•™ìƒë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ensemble_name}")
        
        print(f"ğŸ“Š ì•™ìƒë¸” í‰ê°€ ì¤‘: {ensemble_name}")
        
        ensemble = self.ensembles[ensemble_name]
        
        if isinstance(ensemble, AdvancedTTAEnsemble):
            # TTA ì•™ìƒë¸”ì€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‰ê°€
            print("âš ï¸ TTA ì•™ìƒë¸”ì€ ë³„ë„ í‰ê°€ ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return {}
        
        predictions, probabilities = ensemble.predict(val_loader)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        accuracy = accuracy_score(val_targets, predictions)
        f1_macro = f1_score(val_targets, predictions, average='macro')
        f1_weighted = f1_score(val_targets, predictions, average='weighted')
        
        results = {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'confidence_mean': np.mean(np.max(probabilities, axis=1)),
            'confidence_std': np.std(np.max(probabilities, axis=1))
        }
        
        print(f"âœ… ì•™ìƒë¸” í‰ê°€ ì™„ë£Œ:")
        print(f"   ì •í™•ë„: {accuracy:.4f}")
        print(f"   F1 (Macro): {f1_macro:.4f}")
        print(f"   F1 (Weighted): {f1_weighted:.4f}")
        
        return results
    
    def save_ensemble_config(self, ensemble_name: str, config_path: str):
        """ì•™ìƒë¸” ì„¤ì • ì €ì¥"""
        if ensemble_name not in self.ensembles:
            raise ValueError(f"ì•™ìƒë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ensemble_name}")
        
        config = {
            'ensemble_name': ensemble_name,
            'ensemble_type': type(self.ensembles[ensemble_name]).__name__,
            'model_count': len(self.ensembles[ensemble_name].models) if hasattr(self.ensembles[ensemble_name], 'models') else 1,
            'created_at': pd.Timestamp.now().isoformat()
        }
        
        with open(config_path, 'w') as f:
            import json
            json.dump(config, f, indent=2)
        
        print(f"ğŸ’¾ ì•™ìƒë¸” ì„¤ì • ì €ì¥: {config_path}")


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("ğŸ­ ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    # ì•™ìƒë¸” ê´€ë¦¬ì ìƒì„±
    manager = EnsembleManager("/home/james/doc-classification/computervisioncompetition-cv3/workspaces/jaehong")
    
    # ì˜ˆì‹œ ëª¨ë¸ ì„¤ì •ë“¤
    model_configs = {
        'efficientnet_b3': {
            'architecture': 'efficientnet_b3',
            'num_classes': 17,
            'dropout_rate': 0.4
        },
        'efficientnet_b4': {
            'architecture': 'efficientnet_b4', 
            'num_classes': 17,
            'dropout_rate': 0.4
        },
        'convnext_base': {
            'architecture': 'convnext_base',
            'num_classes': 17,
            'dropout_rate': 0.4
        }
    }
    
    print(f"âœ… ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    print(f"   ì§€ì› ì•™ìƒë¸” íƒ€ì…: Voting, Stacking, TTA")
    print(f"   ëª¨ë¸ ì„¤ì •: {len(model_configs)}ê°œ ì¤€ë¹„")
