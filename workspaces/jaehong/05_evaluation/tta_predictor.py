"""
ğŸ”® Advanced TTA Prediction System
ì‹œë‹ˆì–´ ê·¸ëœë“œë§ˆìŠ¤í„° ìˆ˜ì¤€ì˜ TTA ì˜ˆì¸¡ ì‹œìŠ¤í…œ

Features:
- 8ê°€ì§€ TTA ì „ëµ
- ê°€ì¤‘ í‰ê·  ê²°í•©
- ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
- GPU ìµœì í™”
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import cv2
from tqdm import tqdm

# 04_training ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.insert(0, str(Path(__file__).parent.parent / "04_training"))
from model import DocumentClassifier, ModelFactory


class TTADataset(Dataset):
    """TTAìš© ë°ì´í„°ì…‹"""
    
    def __init__(self, image_paths: List[str], transforms: List[A.Compose]):
        """
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            transforms: TTA ë³€í™˜ ë¦¬ìŠ¤íŠ¸
        """
        self.image_paths = image_paths
        self.transforms = transforms
        self.n_tta = len(transforms)
    
    def __len__(self):
        return len(self.image_paths) * self.n_tta
    
    def __getitem__(self, idx):
        # ì‹¤ì œ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ì™€ TTA ì¸ë±ìŠ¤ ê³„ì‚°
        img_idx = idx // self.n_tta
        tta_idx = idx % self.n_tta
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_paths[img_idx]
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # TTA ë³€í™˜ ì ìš©
        transformed = self.transforms[tta_idx](image=image)
        
        return {
            'image': transformed['image'],
            'img_idx': img_idx,
            'tta_idx': tta_idx,
            'image_path': str(image_path)
        }


class TTATransformFactory:
    """TTA ë³€í™˜ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_tta_transforms(image_size: int = 512) -> List[A.Compose]:
        """8ê°€ì§€ TTA ë³€í™˜ ìƒì„±"""
        
        # ê¸°ë³¸ ì •ê·œí™”
        normalize = A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        
        transforms = []
        
        # 1. ì›ë³¸
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            normalize,
            ToTensorV2()
        ]))
        
        # 2. ìˆ˜í‰ ë’¤ì§‘ê¸°
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.HorizontalFlip(p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 3. 5ë„ íšŒì „
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.Rotate(limit=(5, 5), p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 4. -5ë„ íšŒì „  
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.Rotate(limit=(-5, -5), p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 5. ë°ê¸° ì¦ê°€
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.RandomBrightnessContrast(brightness_limit=(0.1, 0.1), contrast_limit=0, p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 6. ë°ê¸° ê°ì†Œ
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.RandomBrightnessContrast(brightness_limit=(-0.1, -0.1), contrast_limit=0, p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 7. ëŒ€ë¹„ ì¦ê°€
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=(0.1, 0.1), p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        # 8. ëŒ€ë¹„ ê°ì†Œ
        transforms.append(A.Compose([
            A.Resize(image_size, image_size),
            A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=(-0.1, -0.1), p=1.0),
            normalize,
            ToTensorV2()
        ]))
        
        return transforms


class TTAPredictor:
    """ê³ ê¸‰ TTA ì˜ˆì¸¡ê¸°"""
    
    def __init__(
        self,
        model: torch.nn.Module,
        device: str = "cuda",
        tta_weights: Optional[List[float]] = None
    ):
        """
        Args:
            model: ì˜ˆì¸¡ ëª¨ë¸
            device: ë””ë°”ì´ìŠ¤
            tta_weights: TTAë³„ ê°€ì¤‘ì¹˜
        """
        self.model = model.to(device)
        self.device = device
        self.model.eval()
        
        # TTA ê°€ì¤‘ì¹˜ (ì›ë³¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        if tta_weights is None:
            self.tta_weights = [0.3, 0.15, 0.1, 0.1, 0.1, 0.1, 0.075, 0.075]
        else:
            self.tta_weights = tta_weights
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.tta_weights)
        self.tta_weights = [w / total_weight for w in self.tta_weights]
        
        print(f"ğŸ”® TTA ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”:")
        print(f"   ë””ë°”ì´ìŠ¤: {device}")
        print(f"   TTA ìˆ˜: {len(self.tta_weights)}")
        print(f"   ê°€ì¤‘ì¹˜: {[f'{w:.3f}' for w in self.tta_weights]}")
    
    def predict_with_tta(
        self,
        image_paths: List[str],
        image_size: int = 512,
        batch_size: int = 32,
        confidence_threshold: float = 0.0
    ) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
        """
        TTAë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡
        
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            image_size: ì´ë¯¸ì§€ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            predictions: ì˜ˆì¸¡ í´ë˜ìŠ¤
            probabilities: ì˜ˆì¸¡ í™•ë¥ 
            stats: í†µê³„ ì •ë³´
        """
        print(f"ğŸ”® TTA ì˜ˆì¸¡ ì‹œì‘:")
        print(f"   ì´ë¯¸ì§€ ìˆ˜: {len(image_paths)}")
        print(f"   TTA ìˆ˜: {len(self.tta_weights)}")
        print(f"   ì´ ì˜ˆì¸¡: {len(image_paths) * len(self.tta_weights)}")
        
        # TTA ë³€í™˜ ìƒì„±
        tta_transforms = TTATransformFactory.create_tta_transforms(image_size)
        
        # TTA ë°ì´í„°ì…‹ ìƒì„±
        tta_dataset = TTADataset(image_paths, tta_transforms)
        tta_loader = DataLoader(
            tta_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        all_predictions = []
        all_image_indices = []
        all_tta_indices = []
        
        with torch.no_grad():
            for batch in tqdm(tta_loader, desc="TTA ì˜ˆì¸¡"):
                images = batch['image'].to(self.device, non_blocking=True)
                img_indices = batch['img_idx'].cpu().numpy()
                tta_indices = batch['tta_idx'].cpu().numpy()
                
                # ëª¨ë¸ ì˜ˆì¸¡
                logits = self.model(images)
                probs = F.softmax(logits, dim=1)
                
                all_predictions.append(probs.cpu().numpy())
                all_image_indices.extend(img_indices)
                all_tta_indices.extend(tta_indices)
        
        # ì˜ˆì¸¡ ê²°í•©
        all_predictions = np.vstack(all_predictions)
        
        # ì´ë¯¸ì§€ë³„ë¡œ TTA ê²°ê³¼ ì§‘ê³„
        final_probabilities = np.zeros((len(image_paths), all_predictions.shape[1]))
        confidence_scores = np.zeros(len(image_paths))
        
        for i in range(len(image_paths)):
            # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ëª¨ë“  TTA ì˜ˆì¸¡ ìˆ˜ì§‘
            mask = np.array(all_image_indices) == i
            image_predictions = all_predictions[mask]
            image_tta_indices = np.array(all_tta_indices)[mask]
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_probs = np.zeros_like(image_predictions[0])
            for pred, tta_idx in zip(image_predictions, image_tta_indices):
                weight = self.tta_weights[tta_idx]
                weighted_probs += pred * weight
            
            final_probabilities[i] = weighted_probs
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ìµœëŒ€ í™•ë¥ )
            confidence_scores[i] = np.max(weighted_probs)
        
        # ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤
        final_predictions = np.argmax(final_probabilities, axis=1)
        
        # ì‹ ë¢°ë„ í•„í„°ë§
        if confidence_threshold > 0:
            low_confidence_mask = confidence_scores < confidence_threshold
            low_confidence_count = np.sum(low_confidence_mask)
            print(f"âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ ì˜ˆì¸¡: {low_confidence_count}ê°œ (ì„ê³„ê°’: {confidence_threshold})")
        
        # í†µê³„ ì •ë³´
        stats = {
            'total_images': len(image_paths),
            'total_tta_predictions': len(all_predictions),
            'mean_confidence': float(np.mean(confidence_scores)),
            'std_confidence': float(np.std(confidence_scores)),
            'min_confidence': float(np.min(confidence_scores)),
            'max_confidence': float(np.max(confidence_scores)),
            'low_confidence_count': int(np.sum(confidence_scores < confidence_threshold)) if confidence_threshold > 0 else 0,
            'tta_weights': self.tta_weights,
            'class_distribution': {
                int(cls): int(count) for cls, count in 
                zip(*np.unique(final_predictions, return_counts=True))
            }
        }
        
        print(f"âœ… TTA ì˜ˆì¸¡ ì™„ë£Œ:")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence']:.4f}")
        print(f"   ì‹ ë¢°ë„ ë²”ìœ„: [{stats['min_confidence']:.4f}, {stats['max_confidence']:.4f}]")
        
        return final_predictions, final_probabilities, stats
    
    def predict_single_image(
        self,
        image_path: str,
        image_size: int = 512
    ) -> Tuple[int, np.ndarray, Dict[str, Any]]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ TTA ì˜ˆì¸¡"""
        
        predictions, probabilities, stats = self.predict_with_tta(
            [image_path], image_size, batch_size=8
        )
        
        return predictions[0], probabilities[0], {
            'confidence': stats['mean_confidence'],
            'tta_weights': self.tta_weights
        }
    
    def analyze_tta_contribution(
        self,
        image_paths: List[str],
        sample_size: int = 100,
        image_size: int = 512
    ) -> Dict[str, Any]:
        """TTA ê¸°ì—¬ë„ ë¶„ì„"""
        
        if len(image_paths) > sample_size:
            # ìƒ˜í”Œë§
            indices = np.random.choice(len(image_paths), sample_size, replace=False)
            sample_paths = [image_paths[i] for i in indices]
        else:
            sample_paths = image_paths
        
        print(f"ğŸ” TTA ê¸°ì—¬ë„ ë¶„ì„ (ìƒ˜í”Œ: {len(sample_paths)}ê°œ)")
        
        # ê° TTAë³„ ê°œë³„ ì˜ˆì¸¡
        tta_transforms = TTATransformFactory.create_tta_transforms(image_size)
        tta_names = ["original", "h_flip", "rotate_5", "rotate_-5", 
                    "bright_up", "bright_down", "contrast_up", "contrast_down"]
        
        tta_results = {}
        
        for tta_idx, (transform, name) in enumerate(zip(tta_transforms, tta_names)):
            dataset = TTADataset(sample_paths, [transform])
            loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)
            
            predictions = []
            confidences = []
            
            with torch.no_grad():
                for batch in loader:
                    images = batch['image'].to(self.device)
                    logits = self.model(images)
                    probs = F.softmax(logits, dim=1)
                    
                    pred_classes = torch.argmax(probs, dim=1)
                    pred_confidences = torch.max(probs, dim=1)[0]
                    
                    predictions.extend(pred_classes.cpu().numpy())
                    confidences.extend(pred_confidences.cpu().numpy())
            
            tta_results[name] = {
                'predictions': predictions,
                'mean_confidence': float(np.mean(confidences)),
                'weight': self.tta_weights[tta_idx]
            }
        
        # ì¼ì¹˜ìœ¨ ë¶„ì„
        original_preds = tta_results['original']['predictions']
        agreement_rates = {}
        
        for name, result in tta_results.items():
            if name != 'original':
                agreement = np.mean(np.array(result['predictions']) == np.array(original_preds))
                agreement_rates[name] = float(agreement)
        
        analysis = {
            'tta_results': tta_results,
            'agreement_with_original': agreement_rates,
            'best_tta_by_confidence': max(tta_results.keys(), 
                                        key=lambda x: tta_results[x]['mean_confidence']),
            'sample_size': len(sample_paths)
        }
        
        print(f"âœ… TTA ë¶„ì„ ì™„ë£Œ:")
        print(f"   ìµœê³  ì‹ ë¢°ë„ TTA: {analysis['best_tta_by_confidence']}")
        print(f"   ì›ë³¸ê³¼ í‰ê·  ì¼ì¹˜ìœ¨: {np.mean(list(agreement_rates.values())):.3f}")
        
        return analysis


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ”® TTA ì˜ˆì¸¡ê¸° í…ŒìŠ¤íŠ¸ëŠ” main_evaluation.pyì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
