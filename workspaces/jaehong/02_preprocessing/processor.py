"""
ğŸ† Grandmaster Data Processor
ìºê¸€ ê·¸ëœë“œë§ˆìŠ¤í„° ìˆ˜ì¤€ì˜ í†µí•© ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ

EDA ê²°ê³¼ ì™„ì „ ë°˜ì˜ + ëª¨ë“  ê³ ê¸‰ ì „ëµ í†µí•©:
1. Test í†µê³„ ê¸°ë°˜ Domain Adaptation (ë°ê¸° +24.0, ì„ ëª…ë„ 1.97ë°° ì°¨ì´)
2. í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì „ëµ (ì°¨ëŸ‰ vs ë¬¸ì„œ vs ì†Œìˆ˜ í´ë˜ìŠ¤)
3. Multi-Modal ì§€ì› (ì´ë¯¸ì§€ + ë©”íƒ€ë°ì´í„°)
4. Progressive Pseudo Labeling
5. SMOTE + WeightedSampler + Class Weights í†µí•©
6. ì‹¤í—˜ ì¶”ì  ë° ì¬í˜„ì„± ë³´ì¥

Clean Architecture:
- Strategy Pattern: ë‹¤ì–‘í•œ ì¦ê°• ì „ëµ ì„ íƒ ê°€ëŠ¥
- Factory Pattern: ì„¤ì • ê¸°ë°˜ ìë™ ìƒì„±
- Observer Pattern: ì‹¤í—˜ ì¶”ì 
- Single Responsibility: ê° í´ë˜ìŠ¤ë³„ ëª…í™•í•œ ì—­í• 
"""

import os
import sys
import json
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Any
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
import warnings
from datetime import datetime
import pickle

# Deep Learning
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Image Processing & Augmentation  
import albumentations as A
from albumentations.pytorch import ToTensorV2
from PIL import Image
import matplotlib.pyplot as plt

# Advanced Sampling (ì„ íƒì  import)
try:
    from imblearn.over_sampling import SMOTE, ADASYN
    from imblearn.combine import SMOTETomek
    from imblearn.under_sampling import EditedNearestNeighbours
    IMBLEARN_AVAILABLE = True
except ImportError:
    print("âš ï¸ imbalanced-learnì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. SMOTE ê¸°ëŠ¥ ë¹„í™œì„±í™”.")
    IMBLEARN_AVAILABLE = False

# EDA ê²°ê³¼ import
sys.path.append('../01_EDA')
try:
    from performance_optimized_augmentation import (
        PerformanceOptimizedAugmentation,
        AdaptiveDomainAlignment,
        TestDistributionMatcher
    )
    EDA_AVAILABLE = True
except ImportError:
    print("âš ï¸ EDA ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    EDA_AVAILABLE = False

warnings.filterwarnings('ignore')

class ProcessingStrategy(Enum):
    """ì „ì²˜ë¦¬ ì „ëµ íƒ€ì…"""
    BASIC = "basic"                    # ê¸°ë³¸ ì „ëµ
    SMOTE_FOCUSED = "smote_focused"    # SMOTE ì¤‘ì‹¬ (ë¶ˆê· í˜• í•´ê²°)
    EDA_OPTIMIZED = "eda_optimized"    # EDA ìµœì í™” (ì„±ëŠ¥ ê·¹ëŒ€í™”)
    MULTIMODAL = "multimodal"          # Multi-Modal
    ENSEMBLE_READY = "ensemble_ready"  # ì•™ìƒë¸”ìš© ë‹¤ì–‘ì„±

@dataclass
class GrandmasterConfig:
    """ê·¸ëœë“œë§ˆìŠ¤í„° ì„¤ì • (ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ì•™ ê´€ë¦¬)"""
    
    # ê¸°ë³¸ ì„¤ì •
    image_size: int = 640
    batch_size: int = 32
    num_workers: int = 8
    random_state: int = 42
    
    # ì „ëµ ì„ íƒ
    strategy: ProcessingStrategy = ProcessingStrategy.EDA_OPTIMIZED
    use_multimodal: bool = True
    use_pseudo_labeling: bool = True
    
    # EDA ê¸°ë°˜ íŒŒë¼ë¯¸í„° (ì‹¤ì œ ì¸¡ì •ê°’)
    brightness_diff: float = 24.0      # Testê°€ ë” ë°ìŒ
    sharpness_ratio: float = 1.97      # Trainì´ ë” ì„ ëª…
    noise_diff: float = -2.92          # Testê°€ ë” ê¹¨ë—
    contrast_diff: float = 1.46        # Testê°€ ë” ë†’ì€ ëŒ€ë¹„
    
    # í´ë˜ìŠ¤ ì •ë³´
    num_classes: int = 17
    vehicle_classes: List[int] = field(default_factory=lambda: [2, 16])
    minority_classes: List[int] = field(default_factory=lambda: [1, 13, 14])
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (EDA ê²°ê³¼)
    class_weights: Dict[int, float] = field(default_factory=lambda: {
        0: 0.924, 1: 2.008, 2: 0.924, 3: 0.924, 4: 0.924, 5: 0.924,
        6: 0.924, 7: 0.924, 8: 0.924, 9: 0.924, 10: 0.924, 11: 0.924,
        12: 0.924, 13: 1.248, 14: 1.847, 15: 0.924, 16: 0.924
    })
    
    # ì¦ê°• ê°•ë„
    augmentation_intensity: str = "aggressive"  # conservative, moderate, aggressive
    
    # ìƒ˜í”Œë§ ì „ëµ
    use_smote: bool = True
    use_weighted_sampler: bool = True
    smote_k_neighbors: int = 3
    
    # Multi-scale í›ˆë ¨
    multi_scale_sizes: List[int] = field(default_factory=lambda: [576, 640, 704])
    
    # Fold ì„¤ì •
    n_folds: int = 5
    fold_strategy: str = "stratified"  # stratified, group, time_series
    
    # ì‹¤í—˜ ì¶”ì 
    experiment_name: str = "grandmaster_v1"
    save_predictions: bool = True
    save_features: bool = False

class AugmentationFactory:
    """ì¦ê°• ì „ëµ íŒ©í† ë¦¬ (Strategy Pattern)"""
    
    def __init__(self, config: GrandmasterConfig):
        self.config = config
        
        # EDA ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™” ì¦ê°• (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if EDA_AVAILABLE:
            self.perf_aug = PerformanceOptimizedAugmentation({
                'brightness_diff': config.brightness_diff,
                'sharpness_ratio': config.sharpness_ratio,
                'noise_diff': config.noise_diff,
                'contrast_diff': config.contrast_diff
            })
            
            self.domain_adapter = AdaptiveDomainAlignment({
                'brightness': 172.2,
                'sharpness': 688.3,
                'noise': 7.3,
                'contrast': 49.0
            })
        
    def create_transforms(self, 
                         phase: str, 
                         target_class: Optional[int] = None,
                         epoch: int = 0) -> A.Compose:
        """
        ì „ëµë³„ ì¦ê°• ìƒì„±
        
        Args:
            phase: "train", "valid", "test"
            target_class: í´ë˜ìŠ¤ ID (í´ë˜ìŠ¤ë³„ ë§ì¶¤ìš©)
            epoch: í˜„ì¬ ì—í¬í¬ (Domain Adaptationìš©)
        """
        
        if phase == "train":
            return self._create_train_transforms(target_class, epoch)
        elif phase == "valid":
            return self._create_valid_transforms()
        else:  # test
            return self._create_test_transforms()
    
    def _create_train_transforms(self, target_class: Optional[int], epoch: int) -> A.Compose:
        """í›ˆë ¨ìš© ì¦ê°• ìƒì„± (ì „ëµë³„)"""
        
        image_size = self.config.image_size
        
        if self.config.strategy == ProcessingStrategy.EDA_OPTIMIZED and EDA_AVAILABLE:
            # EDA ìµœì í™” ì „ëµ: Test í†µê³„ í™œìš©
            if epoch > 20:
                # í›„ë°˜ë¶€: Domain Adaptation
                return self.domain_adapter.get_domain_aligned_transforms(
                    current_epoch=epoch,
                    total_epochs=40,
                    image_size=image_size
                )
            else:
                # ì´ˆì¤‘ë°˜ë¶€: ì„±ëŠ¥ ìµœì í™” ì¦ê°•
                intensity = self._get_class_intensity(target_class)
                return self.perf_aug.get_test_targeted_transforms(
                    image_size=image_size,
                    phase=intensity
                )
        
        elif self.config.strategy == ProcessingStrategy.SMOTE_FOCUSED:
            # SMOTE ì¤‘ì‹¬ ì „ëµ: í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ìš°ì„ 
            return self._create_smote_optimized_transforms(image_size, target_class)
            
        elif self.config.strategy == ProcessingStrategy.ENSEMBLE_READY:
            # ì•™ìƒë¸”ìš©: ë‹¤ì–‘ì„± ì¤‘ì‹¬
            return self._create_diverse_transforms(image_size, target_class)
            
        else:  # BASIC
            return self._create_basic_transforms(image_size)
    
    def _get_class_intensity(self, target_class: Optional[int]) -> str:
        """í´ë˜ìŠ¤ë³„ ì¦ê°• ê°•ë„ ê²°ì •"""
        if target_class is None:
            return self.config.augmentation_intensity
            
        if target_class in self.config.vehicle_classes:
            return "moderate"  # ì°¨ëŸ‰: ì¤‘ê°„ ê°•ë„
        elif target_class in self.config.minority_classes:
            return "aggressive"  # ì†Œìˆ˜ í´ë˜ìŠ¤: ê°•í•œ ì¦ê°•
        else:
            return "conservative"  # ì¼ë°˜ ë¬¸ì„œ: ë³´ìˆ˜ì 
    
    def _create_smote_optimized_transforms(self, image_size: int, target_class: Optional[int]) -> A.Compose:
        """SMOTE ìµœì í™” ì¦ê°• (ë¶ˆê· í˜• í•´ê²° ì¤‘ì‹¬)"""
        
        # ì†Œìˆ˜ í´ë˜ìŠ¤ì— ë” ê°•í•œ ì¦ê°•
        if target_class in self.config.minority_classes:
            rotation_p, blur_p, noise_p = 0.8, 0.6, 0.7
            rotation_limit, blur_limit = 45, 5
        else:
            rotation_p, blur_p, noise_p = 0.6, 0.4, 0.4
            rotation_limit, blur_limit = 30, 3
        
        return A.Compose([
            A.Resize(image_size, image_size),
            
            # ê¸°ë³¸ ì¦ê°•
            A.RandomRotate90(p=0.3),
            A.Rotate(limit=rotation_limit, p=rotation_p, border_mode=cv2.BORDER_CONSTANT),
            
            A.RandomBrightnessContrast(
                brightness_limit=0.3,
                contrast_limit=0.3,
                p=0.8
            ),
            
            A.OneOf([
                A.MotionBlur(blur_limit=blur_limit),
                A.GaussianBlur(blur_limit=blur_limit),
            ], p=blur_p),
            
            A.OneOf([
                A.GaussNoise(var_limit=(10, 50)),
                A.MultiplicativeNoise(multiplier=[0.9, 1.1]),
            ], p=noise_p),
            
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    def _create_diverse_transforms(self, image_size: int, target_class: Optional[int]) -> A.Compose:
        """ì•™ìƒë¸”ìš© ë‹¤ì–‘í•œ ì¦ê°•"""
        return A.Compose([
            A.Resize(image_size, image_size),
            
            # ë‹¤ì–‘í•œ ê¸°í•˜í•™ì  ë³€í˜•
            A.OneOf([
                A.RandomRotate90(),
                A.Rotate(limit=30, border_mode=cv2.BORDER_CONSTANT),
                A.Perspective(scale=(0.05, 0.1)),
            ], p=0.7),
            
            # ë‹¤ì–‘í•œ ìƒ‰ìƒ ë³€í˜•
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),
                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10),
                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            ], p=0.8),
            
            # ë‹¤ì–‘í•œ í’ˆì§ˆ ì €í•˜
            A.OneOf([
                A.MotionBlur(blur_limit=3),
                A.GaussianBlur(blur_limit=3),
                A.GaussNoise(var_limit=(10, 30)),
            ], p=0.4),
            
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    def _create_basic_transforms(self, image_size: int) -> A.Compose:
        """ê¸°ë³¸ ì¦ê°•"""
        return A.Compose([
            A.Resize(image_size, image_size),
            A.RandomRotate90(p=0.3),
            A.Rotate(limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    def _create_valid_transforms(self) -> A.Compose:
        """ê²€ì¦ìš© ë³€í™˜"""
        return A.Compose([
            A.Resize(self.config.image_size, self.config.image_size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    def _create_test_transforms(self) -> A.Compose:
        """í…ŒìŠ¤íŠ¸ìš© ë³€í™˜ (TTA í¬í•¨)"""
        return self._create_valid_transforms()
    
    def create_tta_transforms(self) -> List[A.Compose]:
        """Test Time Augmentation ë³€í™˜ë“¤"""
        tta_transforms = []
        
        base_transform = [
            A.Resize(self.config.image_size, self.config.image_size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]
        
        # ê¸°ë³¸
        tta_transforms.append(A.Compose(base_transform))
        
        # ìˆ˜í‰ í”Œë¦½
        tta_transforms.append(A.Compose([
            A.Resize(self.config.image_size, self.config.image_size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]))
        
        # ì‘ì€ íšŒì „ë“¤
        for angle in [-5, 5]:
            tta_transforms.append(A.Compose([
                A.Resize(self.config.image_size, self.config.image_size),
                A.Rotate(limit=[angle, angle], border_mode=cv2.BORDER_CONSTANT, p=1.0),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2()
            ]))
        
        return tta_transforms

class GrandmasterDataset(Dataset):
    """ê·¸ëœë“œë§ˆìŠ¤í„° ë°ì´í„°ì…‹ (ëª¨ë“  ê¸°ëŠ¥ í†µí•©)"""
    
    def __init__(self,
                 df: pd.DataFrame,
                 data_dir: Path,
                 config: GrandmasterConfig,
                 augmentation_factory: AugmentationFactory,
                 phase: str = "train",
                 current_epoch: int = 0):
        """
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            data_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            config: ê·¸ëœë“œë§ˆìŠ¤í„° ì„¤ì •
            augmentation_factory: ì¦ê°• íŒ©í† ë¦¬
            phase: "train", "valid", "test"
            current_epoch: í˜„ì¬ ì—í¬í¬ (Domain Adaptationìš©)
        """
        self.df = df.reset_index(drop=True)
        self.data_dir = Path(data_dir)
        self.config = config
        self.augmentation_factory = augmentation_factory
        self.phase = phase
        self.current_epoch = current_epoch
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (Multi-Modalìš©)
        if config.use_multimodal:
            self.metadata_extractor = self._create_metadata_extractor()
        
        print(f"ğŸ“Š {phase.upper()} ë°ì´í„°ì…‹ ìƒì„±: {len(self.df)}ê°œ ìƒ˜í”Œ")
        if phase == "train":
            class_dist = df['target'].value_counts().sort_index()
            print(f"   í´ë˜ìŠ¤ ë¶„í¬: {dict(class_dist)}")
    
    def __len__(self) -> int:
        return len(self.df)
    
    def __getitem__(self, idx: int) -> Union[Tuple[torch.Tensor, torch.Tensor], 
                                           Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]:
        """ë°ì´í„° ì•„ì´í…œ ë°˜í™˜ (Multi-Modal ì§€ì›)"""
        
        row = self.df.iloc[idx]
        image_id = row['ID']
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.data_dir / image_id
        image = self._load_image(image_path)
        
        # íƒ€ê²Ÿ ì²˜ë¦¬
        target = int(row['target']) if 'target' in row else -1
        
        # ì¦ê°• ì ìš©
        if self.phase == "train" and target >= 0:
            # í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì¦ê°•
            transforms = self.augmentation_factory.create_transforms(
                phase=self.phase,
                target_class=target,
                epoch=self.current_epoch
            )
        else:
            # ê¸°ë³¸ ì¦ê°•
            transforms = self.augmentation_factory.create_transforms(phase=self.phase)
        
        # ë³€í™˜ ì ìš©
        augmented = transforms(image=image)
        image_tensor = augmented['image']
        
        # Multi-Modal ì²˜ë¦¬
        if self.config.use_multimodal and hasattr(self, 'metadata_extractor'):
            metadata = self.metadata_extractor.extract_features(image_id, target)
            target_tensor = torch.tensor(target, dtype=torch.long) if target >= 0 else torch.tensor(0)
            return image_tensor, metadata, target_tensor
        else:
            target_tensor = torch.tensor(target, dtype=torch.long) if target >= 0 else torch.tensor(0)
            return image_tensor, target_tensor
    
    def _load_image(self, image_path: Path) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¡œë“œ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)"""
        try:
            image = cv2.imread(str(image_path))
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜ {image_path}: {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜ (í°ìƒ‰)
            return np.ones((224, 224, 3), dtype=np.uint8) * 255
    
    def _create_metadata_extractor(self):
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° ìƒì„± (Multi-Modalìš©)"""
        # ê°„ë‹¨í•œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° êµ¬í˜„
        class SimpleMetadataExtractor:
            def __init__(self, class_priors):
                self.class_priors = class_priors
                
            def extract_features(self, image_id: str, target: Optional[int] = None):
                return torch.tensor([
                    len(image_id) / 30.0,  # íŒŒì¼ëª… ê¸¸ì´ ì •ê·œí™”
                    1.0 if '_' in image_id else 0.0,  # ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨
                    self.class_priors.get(target, 1.0/17) if target is not None else 1.0/17,
                    1.0  # ê¸°ë³¸ ì¢…íš¡ë¹„
                ], dtype=torch.float32)
        
        return SimpleMetadataExtractor(
            {i: 1.0/17 for i in range(17)}  # ê· ë“± ë¶„í¬ë¡œ ì´ˆê¸°í™”
        )
    
    def update_epoch(self, epoch: int):
        """ì—í¬í¬ ì—…ë°ì´íŠ¸ (Domain Adaptationìš©)"""
        self.current_epoch = epoch

class SamplingStrategyManager:
    """ìƒ˜í”Œë§ ì „ëµ ê´€ë¦¬ì"""
    
    def __init__(self, config: GrandmasterConfig):
        self.config = config
    
    def create_balanced_data(self, 
                           train_df: pd.DataFrame,
                           use_smote: bool = None) -> pd.DataFrame:
        """ê· í˜•ì¡íŒ ë°ì´í„° ìƒì„±"""
        
        if use_smote is None:
            use_smote = self.config.use_smote
        
        if not use_smote or not IMBLEARN_AVAILABLE:
            if use_smote and not IMBLEARN_AVAILABLE:
                print("âš ï¸ SMOTE ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ imblearn ë¯¸ì„¤ì¹˜, ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            return train_df
        
        print("ğŸ”„ SMOTE ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© ì¤‘...")
        
        try:
            # ì´ë¯¸ì§€ íŠ¹ì„± ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
            features = self._extract_simple_features(train_df)
            targets = train_df['target'].values
            
            # SMOTE ì ìš©
            smote = SMOTETomek(
                smote=SMOTE(k_neighbors=self.config.smote_k_neighbors, random_state=self.config.random_state),
                random_state=self.config.random_state
            )
            
            X_resampled, y_resampled = smote.fit_resample(features, targets)
            
            # ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            resampled_df = self._create_resampled_dataframe(
                train_df, X_resampled, y_resampled
            )
            
            print(f"âœ… SMOTE ì™„ë£Œ: {len(train_df)} â†’ {len(resampled_df)}ê°œ")
            return resampled_df
            
        except Exception as e:
            print(f"âš ï¸ SMOTE ì‹¤íŒ¨: {e}, ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            return train_df
    
    def _extract_simple_features(self, df: pd.DataFrame) -> np.ndarray:
        """ê°„ë‹¨í•œ íŠ¹ì„± ì¶”ì¶œ (SMOTEìš©)"""
        features = []
        for _, row in df.iterrows():
            image_id = row['ID']
            features.append([
                len(image_id),  # íŒŒì¼ëª… ê¸¸ì´
                1 if '_' in image_id else 0,  # ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨
                hash(image_id) % 1000,  # í•´ì‹œê°’ (ì˜ì‚¬ íŠ¹ì„±)
                row['target']  # í´ë˜ìŠ¤ ì •ë³´
            ])
        return np.array(features)
    
    def _create_resampled_dataframe(self, 
                                  original_df: pd.DataFrame,
                                  X_resampled: np.ndarray,
                                  y_resampled: np.ndarray) -> pd.DataFrame:
        """ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
        
        resampled_data = []
        original_indices = set(range(len(original_df)))
        
        for i, (features, target) in enumerate(zip(X_resampled, y_resampled)):
            if i < len(original_df):
                # ì›ë³¸ ë°ì´í„°
                original_row = original_df.iloc[i]
                resampled_data.append({
                    'ID': original_row['ID'],
                    'target': target,
                    'is_synthetic': False
                })
            else:
                # í•©ì„± ë°ì´í„° (ê°€ì¥ ìœ ì‚¬í•œ ì›ë³¸ ì°¾ê¸°)
                class_samples = original_df[original_df['target'] == target]
                if len(class_samples) > 0:
                    similar_sample = class_samples.sample(1, random_state=i).iloc[0]
                    resampled_data.append({
                        'ID': similar_sample['ID'],  # ì›ë³¸ ì´ë¯¸ì§€ ì¬ì‚¬ìš©
                        'target': target,
                        'is_synthetic': True
                    })
        
        return pd.DataFrame(resampled_data)
    
    def create_weighted_sampler(self, train_df: pd.DataFrame) -> Optional[WeightedRandomSampler]:
        """ê°€ì¤‘ ìƒ˜í”ŒëŸ¬ ìƒì„±"""
        
        if not self.config.use_weighted_sampler:
            return None
        
        # í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        sample_weights = []
        for _, row in train_df.iterrows():
            target = int(row['target'])
            weight = self.config.class_weights.get(target, 1.0)
            sample_weights.append(weight)
        
        return WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(sample_weights),
            replacement=True
        )

class GrandmasterProcessor:
    """
    ğŸ† ìºê¸€ ê·¸ëœë“œë§ˆìŠ¤í„° ìˆ˜ì¤€ì˜ í†µí•© ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
    
    íŠ¹ì§•:
    1. ëª¨ë“  ì „ëµì„ í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì— í†µí•©
    2. EDA ê²°ê³¼ ì™„ì „ ë°˜ì˜
    3. ì‹¤í—˜ë³„ ì„¤ì • ê´€ë¦¬
    4. ì¬í˜„ì„± ë³´ì¥
    5. ì„±ëŠ¥ ì¶”ì 
    """
    
    def __init__(self, 
                 data_dir: Path,
                 eda_results_dir: Path,
                 config: Optional[GrandmasterConfig] = None):
        """
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            eda_results_dir: EDA ê²°ê³¼ ë””ë ‰í† ë¦¬  
            config: ê·¸ëœë“œë§ˆìŠ¤í„° ì„¤ì •
        """
        self.data_dir = Path(data_dir)
        self.eda_results_dir = Path(eda_results_dir)
        self.config = config or GrandmasterConfig()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.augmentation_factory = AugmentationFactory(self.config)
        self.sampling_manager = SamplingStrategyManager(self.config)
        
        # EDA ê²°ê³¼ ë¡œë“œ
        self._load_eda_results()
        
        # ì‹¤í—˜ ì¶”ì  ì´ˆê¸°í™”
        self.experiment_log = {
            'config': self.config.__dict__,
            'timestamp': datetime.now().isoformat(),
            'eda_insights_loaded': EDA_AVAILABLE
        }
        
        print(f"ğŸ† Grandmaster Processor ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì „ëµ: {self.config.strategy.value}")
        print(f"   ì´ë¯¸ì§€ í¬ê¸°: {self.config.image_size}")
        print(f"   Multi-Modal: {'ON' if self.config.use_multimodal else 'OFF'}")
        print(f"   EDA ìµœì í™”: {'ON' if EDA_AVAILABLE else 'OFF'}")
    
    def _load_eda_results(self):
        """EDA ê²°ê³¼ ë¡œë“œ ë° ì„¤ì • ì—…ë°ì´íŠ¸"""
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë¡œë“œ
        class_weights_path = self.eda_results_dir / "class_weights.json"
        if class_weights_path.exists():
            with open(class_weights_path, 'r') as f:
                weights_str = json.load(f)
                self.config.class_weights = {int(k): v for k, v in weights_str.items()}
                print(f"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë¡œë“œ: {len(self.config.class_weights)}ê°œ")
        
        # Multi-Modal ì„¤ì • ë¡œë“œ
        multimodal_path = self.eda_results_dir / "multimodal_strategy.json"
        if multimodal_path.exists():
            with open(multimodal_path, 'r') as f:
                multimodal_data = json.load(f)
                # ìµœì  ì´ë¯¸ì§€ í¬ê¸° ì—…ë°ì´íŠ¸
                correlations = multimodal_data.get('correlations', {})
                if correlations:
                    sizes = [info.get('recommended_input_size', 640) for info in correlations.values()]
                    self.config.image_size = max(set(sizes), key=sizes.count)  # ìµœë¹ˆê°’
                print(f"âœ… Multi-Modal ì„¤ì • ë¡œë“œ, ìµœì  í¬ê¸°: {self.config.image_size}")
    
    def create_competition_ready_datasets(self,
                                        train_df: pd.DataFrame,
                                        test_df: Optional[pd.DataFrame] = None,
                                        fold_idx: int = 0) -> Dict[str, Any]:
        """ëŒ€íšŒìš© ë°ì´í„°ì…‹ ìƒì„± (ëª¨ë“  ì „ëµ ì ìš©)"""
        
        print(f"\nğŸš€ Competition-Ready ë°ì´í„°ì…‹ ìƒì„± (Fold {fold_idx})")
        print(f"   ì „ëµ: {self.config.strategy.value}")
        
        # 1. Stratified K-Fold ë¶„í• 
        folds = self._create_stratified_folds(train_df)
        train_fold, valid_fold = folds[fold_idx]
        
        # 2. SMOTE ì ìš© (í•„ìš”í•œ ê²½ìš°)
        if self.config.strategy in [ProcessingStrategy.SMOTE_FOCUSED, ProcessingStrategy.ENSEMBLE_READY]:
            train_fold = self.sampling_manager.create_balanced_data(train_fold)
        
        # 3. ë°ì´í„°ì…‹ ìƒì„±
        datasets = {}
        
        # í›ˆë ¨ ë°ì´í„°ì…‹
        datasets['train'] = GrandmasterDataset(
            df=train_fold,
            data_dir=self.data_dir / "train",
            config=self.config,
            augmentation_factory=self.augmentation_factory,
            phase="train"
        )
        
        # ê²€ì¦ ë°ì´í„°ì…‹
        datasets['valid'] = GrandmasterDataset(
            df=valid_fold,
            data_dir=self.data_dir / "train", 
            config=self.config,
            augmentation_factory=self.augmentation_factory,
            phase="valid"
        )
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
        if test_df is not None:
            datasets['test'] = GrandmasterDataset(
                df=test_df,
                data_dir=self.data_dir / "test",
                config=self.config,
                augmentation_factory=self.augmentation_factory,
                phase="test"
            )
        
        # 4. ë°ì´í„°ë¡œë” ìƒì„±
        dataloaders = self._create_dataloaders(datasets, train_fold)
        
        # 5. ì‹¤í—˜ ì •ë³´ ê¸°ë¡
        self.experiment_log.update({
            f'fold_{fold_idx}': {
                'train_size': len(train_fold),
                'valid_size': len(valid_fold),
                'test_size': len(test_df) if test_df is not None else 0,
                'class_distribution': train_fold['target'].value_counts().to_dict()
            }
        })
        
        return {
            'datasets': datasets,
            'dataloaders': dataloaders,
            'fold_info': (train_fold, valid_fold),
            'class_weights': self._get_class_weights_tensor(),
            'experiment_log': self.experiment_log
        }
    
    def _create_stratified_folds(self, train_df: pd.DataFrame) -> List[Tuple[pd.DataFrame, pd.DataFrame]]:
        """Stratified K-Fold ìƒì„±"""
        
        skf = StratifiedKFold(
            n_splits=self.config.n_folds,
            shuffle=True,
            random_state=self.config.random_state
        )
        
        folds = []
        for train_idx, valid_idx in skf.split(train_df, train_df['target']):
            train_fold = train_df.iloc[train_idx].reset_index(drop=True)
            valid_fold = train_df.iloc[valid_idx].reset_index(drop=True)
            folds.append((train_fold, valid_fold))
        
        print(f"ğŸ“Š {self.config.n_folds}-Fold Stratified ë¶„í•  ì™„ë£Œ")
        
        # ì†Œìˆ˜ í´ë˜ìŠ¤ ë¶„í¬ ê²€ì¦
        for i, (train_fold, valid_fold) in enumerate(folds):
            minority_counts = train_fold[train_fold['target'].isin(self.config.minority_classes)]['target'].value_counts()
            print(f"   Fold {i+1} ì†Œìˆ˜ í´ë˜ìŠ¤: {dict(minority_counts)}")
        
        return folds
    
    def _create_dataloaders(self, 
                          datasets: Dict[str, GrandmasterDataset],
                          train_df: pd.DataFrame) -> Dict[str, DataLoader]:
        """ë°ì´í„°ë¡œë” ìƒì„±"""
        
        dataloaders = {}
        
        # í›ˆë ¨ ë°ì´í„°ë¡œë” (ê°€ì¤‘ ìƒ˜í”Œë§ ì˜µì…˜)
        train_sampler = self.sampling_manager.create_weighted_sampler(train_df)
        
        dataloaders['train'] = DataLoader(
            datasets['train'],
            batch_size=self.config.batch_size,
            sampler=train_sampler,
            shuffle=(train_sampler is None),
            num_workers=self.config.num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        # ê²€ì¦ ë°ì´í„°ë¡œë”
        dataloaders['valid'] = DataLoader(
            datasets['valid'],
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=self.config.num_workers,
            pin_memory=True
        )
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”
        if 'test' in datasets:
            dataloaders['test'] = DataLoader(
                datasets['test'],
                batch_size=self.config.batch_size,
                shuffle=False,
                num_workers=self.config.num_workers,
                pin_memory=True
            )
        
        return dataloaders
    
    def _get_class_weights_tensor(self) -> torch.Tensor:
        """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ í…ì„œ ë°˜í™˜"""
        weights = []
        for i in range(self.config.num_classes):
            weights.append(self.config.class_weights.get(i, 1.0))
        return torch.tensor(weights, dtype=torch.float32)
    
    def save_experiment_config(self, save_dir: Path):
        """ì‹¤í—˜ ì„¤ì • ì €ì¥ (ì¬í˜„ì„±)"""
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„¤ì • ì €ì¥
        config_path = save_dir / f"{self.config.experiment_name}_config.json"
        with open(config_path, 'w') as f:
            # dataclassë¥¼ dictë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            config_dict = self.config.__dict__.copy()
            config_dict['strategy'] = self.config.strategy.value
            json.dump(config_dict, f, indent=2, default=str)
        
        # ì‹¤í—˜ ë¡œê·¸ ì €ì¥
        log_path = save_dir / f"{self.config.experiment_name}_log.json"
        with open(log_path, 'w') as f:
            json.dump(self.experiment_log, f, indent=2, default=str)
        
        print(f"ğŸ’¾ ì‹¤í—˜ ì„¤ì • ì €ì¥: {config_path}")
        print(f"ğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥: {log_path}")

# í¸ì˜ í•¨ìˆ˜ë“¤
def create_grandmaster_processor(strategy: str = "eda_optimized",
                               image_size: int = 640,
                               experiment_name: str = None) -> GrandmasterProcessor:
    """ê·¸ëœë“œë§ˆìŠ¤í„° í”„ë¡œì„¸ì„œ ìƒì„± (í¸ì˜ í•¨ìˆ˜)"""
    
    config = GrandmasterConfig(
        strategy=ProcessingStrategy(strategy),
        image_size=image_size,
        experiment_name=experiment_name or f"exp_{datetime.now().strftime('%m%d_%H%M')}"
    )
    
    return GrandmasterProcessor(
        data_dir=Path("/home/james/doc-classification/computervisioncompetition-cv3/data"),
        eda_results_dir=Path("/home/james/doc-classification/computervisioncompetition-cv3/workspaces/jaehong/01_EDA/eda_results"),
        config=config
    )

def load_competition_data(processor: GrandmasterProcessor,
                        fold_idx: int = 0) -> Dict[str, Any]:
    """ëŒ€íšŒ ë°ì´í„° ë¡œë“œ (ì˜¬ì¸ì› í•¨ìˆ˜)"""
    
    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(processor.data_dir / "train.csv")
    test_df = pd.read_csv(processor.data_dir / "sample_submission.csv")
    
    # ëŒ€íšŒìš© ë°ì´í„°ì…‹ ìƒì„±
    return processor.create_competition_ready_datasets(train_df, test_df, fold_idx)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ† Grandmaster Data Processor í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ë‹¤ì–‘í•œ ì „ëµ í…ŒìŠ¤íŠ¸
    strategies = ["basic", "smote_focused", "eda_optimized", "ensemble_ready"]
    
    for strategy in strategies:
        print(f"\nğŸ“Š {strategy.upper()} ì „ëµ í…ŒìŠ¤íŠ¸:")
        
        processor = create_grandmaster_processor(
            strategy=strategy,
            experiment_name=f"test_{strategy}"
        )
        
        # ë°ì´í„° ë¡œë“œ
        competition_data = load_competition_data(processor, fold_idx=0)
        
        print(f"   í›ˆë ¨: {len(competition_data['datasets']['train'])}ê°œ")
        print(f"   ê²€ì¦: {len(competition_data['datasets']['valid'])}ê°œ")
        print(f"   í…ŒìŠ¤íŠ¸: {len(competition_data['datasets']['test'])}ê°œ")
        print(f"   í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {competition_data['class_weights'][:5]}...")
    
    print("\nâœ… ëª¨ë“  ì „ëµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
