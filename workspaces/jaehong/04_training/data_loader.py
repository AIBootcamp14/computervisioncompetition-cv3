"""
ğŸ—ƒï¸ Advanced Data Loading System
ì‹œë‹ˆì–´ ìºê¸€ëŸ¬ ìˆ˜ì¤€ì˜ ë°ì´í„° ë¡œë”© ë° ì¦ê°• ì‹œìŠ¤í…œ

Features:
- 02_preprocessing ê²°ê³¼ ì—°ê³„
- 01_EDA ì „ëµ ê¸°ë°˜ ì¦ê°•
- Stratified K-Fold ì§€ì›
- Memory-efficient loading
- Advanced augmentations
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Callable
import albumentations as A
from albumentations.pytorch import ToTensorV2

import torch
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from sklearn.model_selection import StratifiedKFold
from PIL import Image

from config import ConfigManager


class DocumentDataset(Dataset):
    """ê³ ì„±ëŠ¥ ë¬¸ì„œ ë¶„ë¥˜ ë°ì´í„°ì…‹"""
    
    def __init__(
        self,
        df: pd.DataFrame,
        image_dir: str,
        transform: Optional[Callable] = None,
        mode: str = "train"
    ):
        """
        Args:
            df: ë°ì´í„°í”„ë ˆì„ (ID, target ì»¬ëŸ¼ í•„ìš”)
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            transform: ë³€í™˜ í•¨ìˆ˜
            mode: ëª¨ë“œ ("train", "val", "test")
        """
        self.df = df.reset_index(drop=True)
        self.image_dir = Path(image_dir)
        self.transform = transform
        self.mode = mode
        
    def __len__(self) -> int:
        return len(self.df)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        row = self.df.iloc[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_dir / row['ID']
        image = self._load_image(image_path)
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            transformed = self.transform(image=image)
            image = transformed['image']
        
        # ê²°ê³¼ êµ¬ì„±
        result = {'image': image, 'image_id': row['ID']}
        
        if 'target' in row and self.mode != "test":
            result['target'] = torch.tensor(row['target'], dtype=torch.long)
            
        return result
    
    def _load_image(self, image_path: Path) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¡œë“œ (OpenCV ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”)"""
        try:
            # OpenCVë¡œ ë¹ ë¥¸ ë¡œë”©
            image = cv2.imread(str(image_path))
            if image is None:
                raise ValueError(f"Cannot load image: {image_path}")
            
            # BGR -> RGB ë³€í™˜
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            return image
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}, ì˜¤ë¥˜: {e}")
            # ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜
            return np.ones((512, 512, 3), dtype=np.uint8) * 128


class AugmentationFactory:
    """01_EDA ì „ëµ ê¸°ë°˜ ì¦ê°• íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_train_transform(image_size: int = 512, augmentation_level: str = "medium") -> A.Compose:
        """í›ˆë ¨ìš© ì¦ê°• ìƒì„±"""
        
        # ê¸°ë³¸ ì¦ê°• (í•­ìƒ ì ìš©)
        base_transforms = [
            A.Resize(image_size, image_size),
            A.HorizontalFlip(p=0.5),
        ]
        
        # ë ˆë²¨ë³„ ì¦ê°•
        if augmentation_level == "light":
            augmentations = [
                A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
                A.Rotate(limit=10, p=0.3),
            ]
        elif augmentation_level == "medium":
            augmentations = [
                # 01_EDA ì „ëµ ê¸°ë°˜
                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),
                A.Rotate(limit=30, p=0.5),  # Test ë°ì´í„° íšŒì „ ëŒ€ì‘
                A.GaussNoise(var_limit=(10, 50), p=0.3),  # Test ë…¸ì´ì¦ˆ ëŒ€ì‘
                A.OneOf([
                    A.MotionBlur(blur_limit=3, p=1.0),
                    A.GaussianBlur(blur_limit=3, p=1.0),
                ], p=0.3),
                A.Perspective(scale=(0.05, 0.1), p=0.3),  # ë¬¸ì„œ ì™œê³¡ ì‹œë®¬ë ˆì´ì…˜
                A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.3),  # ë¶€ë¶„ ê°€ë¦¼ ëŒ€ì‘
            ]
        elif augmentation_level == "heavy":
            augmentations = [
                A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),
                A.Rotate(limit=45, p=0.7),
                A.GaussNoise(var_limit=(10, 100), p=0.5),
                A.OneOf([
                    A.MotionBlur(blur_limit=5, p=1.0),
                    A.GaussianBlur(blur_limit=5, p=1.0),
                    A.MedianBlur(blur_limit=3, p=1.0),
                ], p=0.5),
                A.Perspective(scale=(0.05, 0.15), p=0.5),
                A.CoarseDropout(max_holes=2, max_height=64, max_width=64, p=0.5),
                A.GridDistortion(p=0.3),
                A.OpticalDistortion(p=0.3),
            ]
        else:  # "none"
            augmentations = []
        
        # ì •ê·œí™” ë° í…ì„œ ë³€í™˜ (í•­ìƒ ë§ˆì§€ë§‰)
        final_transforms = [
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]
        
        return A.Compose(base_transforms + augmentations + final_transforms)
    
    @staticmethod
    def create_val_transform(image_size: int = 512) -> A.Compose:
        """ê²€ì¦ìš© ë³€í™˜ ìƒì„±"""
        return A.Compose([
            A.Resize(image_size, image_size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    
    @staticmethod
    def create_tta_transforms(image_size: int = 512, n_tta: int = 4) -> List[A.Compose]:
        """TTAìš© ë³€í™˜ë“¤ ìƒì„±"""
        tta_transforms = []
        
        # ê¸°ë³¸ ë³€í™˜
        tta_transforms.append(AugmentationFactory.create_val_transform(image_size))
        
        if n_tta > 1:
            # ìˆ˜í‰ ë’¤ì§‘ê¸°
            tta_transforms.append(A.Compose([
                A.Resize(image_size, image_size),
                A.HorizontalFlip(p=1.0),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ]))
        
        if n_tta > 2:
            # ì•½ê°„ì˜ íšŒì „
            tta_transforms.append(A.Compose([
                A.Resize(image_size, image_size),
                A.Rotate(limit=5, p=1.0),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ]))
        
        if n_tta > 3:
            # ë°ê¸° ì¡°ì •
            tta_transforms.append(A.Compose([
                A.Resize(image_size, image_size),
                A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),
                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ToTensorV2(),
            ]))
        
        return tta_transforms[:n_tta]


class DataLoaderFactory:
    """ë°ì´í„° ë¡œë” íŒ©í† ë¦¬"""
    
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.data_root = config_manager.data_root
        
    def create_train_val_loaders(
        self,
        batch_size: int = 32,
        val_ratio: float = 0.2,
        image_size: int = 512,
        augmentation_level: str = "medium",
        num_workers: int = 4,
        use_weighted_sampler: bool = True
    ) -> Tuple[DataLoader, DataLoader]:
        """í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±"""
        
        # ë°ì´í„° ë¡œë“œ
        train_df = pd.read_csv(self.data_root / "train.csv")
        
        # Stratified split
        from sklearn.model_selection import train_test_split
        train_idx, val_idx = train_test_split(
            range(len(train_df)),
            test_size=val_ratio,
            stratify=train_df['target'],
            random_state=42
        )
        
        train_subset = train_df.iloc[train_idx].reset_index(drop=True)
        val_subset = train_df.iloc[val_idx].reset_index(drop=True)
        
        print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"   í›ˆë ¨: {len(train_subset)}ê°œ")
        print(f"   ê²€ì¦: {len(val_subset)}ê°œ")
        
        # ë³€í™˜ ìƒì„±
        train_transform = AugmentationFactory.create_train_transform(image_size, augmentation_level)
        val_transform = AugmentationFactory.create_val_transform(image_size)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = DocumentDataset(
            train_subset, self.data_root / "train", train_transform, "train"
        )
        val_dataset = DocumentDataset(
            val_subset, self.data_root / "train", val_transform, "val"
        )
        
        # ìƒ˜í”ŒëŸ¬ ìƒì„± (í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘)
        train_sampler = None
        if use_weighted_sampler:
            train_sampler = self._create_weighted_sampler(train_subset)
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            sampler=train_sampler,
            shuffle=(train_sampler is None),
            num_workers=num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True
        )
        
        return train_loader, val_loader
    
    def create_kfold_loaders(
        self,
        n_splits: int = 5,
        batch_size: int = 32,
        image_size: int = 512,
        augmentation_level: str = "medium",
        num_workers: int = 4
    ) -> List[Tuple[DataLoader, DataLoader]]:
        """K-Fold ë°ì´í„° ë¡œë”ë“¤ ìƒì„±"""
        
        train_df = pd.read_csv(self.data_root / "train.csv")
        
        # Stratified K-Fold
        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
        fold_loaders = []
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):
            print(f"ğŸ“ Fold {fold+1}/{n_splits} ë°ì´í„° ë¡œë” ìƒì„±...")
            
            train_subset = train_df.iloc[train_idx].reset_index(drop=True)
            val_subset = train_df.iloc[val_idx].reset_index(drop=True)
            
            # ë³€í™˜ ìƒì„±
            train_transform = AugmentationFactory.create_train_transform(image_size, augmentation_level)
            val_transform = AugmentationFactory.create_val_transform(image_size)
            
            # ë°ì´í„°ì…‹ ìƒì„±
            train_dataset = DocumentDataset(
                train_subset, self.data_root / "train", train_transform, "train"
            )
            val_dataset = DocumentDataset(
                val_subset, self.data_root / "train", val_transform, "val"
            )
            
            # ë°ì´í„° ë¡œë” ìƒì„±
            train_loader = DataLoader(
                train_dataset,
                batch_size=batch_size,
                shuffle=True,
                num_workers=num_workers,
                pin_memory=True,
                drop_last=True
            )
            
            val_loader = DataLoader(
                val_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                pin_memory=True
            )
            
            fold_loaders.append((train_loader, val_loader))
        
        return fold_loaders
    
    def create_test_loader(
        self,
        batch_size: int = 32,
        image_size: int = 512,
        num_workers: int = 4,
        tta: bool = False,
        n_tta: int = 4
    ) -> Union[DataLoader, List[DataLoader]]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±"""
        
        # ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        sample_df = pd.read_csv(self.data_root / "sample_submission.csv")
        
        if not tta:
            # ì¼ë°˜ í…ŒìŠ¤íŠ¸ ë¡œë”
            test_transform = AugmentationFactory.create_val_transform(image_size)
            test_dataset = DocumentDataset(
                sample_df, self.data_root / "test", test_transform, "test"
            )
            
            return DataLoader(
                test_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                pin_memory=True
            )
        else:
            # TTA í…ŒìŠ¤íŠ¸ ë¡œë”ë“¤
            tta_transforms = AugmentationFactory.create_tta_transforms(image_size, n_tta)
            tta_loaders = []
            
            for i, transform in enumerate(tta_transforms):
                test_dataset = DocumentDataset(
                    sample_df, self.data_root / "test", transform, "test"
                )
                
                tta_loader = DataLoader(
                    test_dataset,
                    batch_size=batch_size,
                    shuffle=False,
                    num_workers=num_workers,
                    pin_memory=True
                )
                tta_loaders.append(tta_loader)
            
            return tta_loaders
    
    def _create_weighted_sampler(self, df: pd.DataFrame) -> WeightedRandomSampler:
        """ê°€ì¤‘ ìƒ˜í”ŒëŸ¬ ìƒì„± (í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘)"""
        class_counts = df['target'].value_counts().sort_index()
        class_weights = self.config_manager.get_class_weights_tensor("cpu").numpy()
        
        # ìƒ˜í”Œë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°
        sample_weights = [class_weights[target] for target in df['target']]
        
        return WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(sample_weights),
            replacement=True
        )


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì • ê´€ë¦¬ì ìƒì„±
    workspace_root = "/home/james/doc-classification/computervisioncompetition-cv3/workspaces/jaehong"
    config_manager = ConfigManager(workspace_root)
    
    # ë°ì´í„° ë¡œë” íŒ©í† ë¦¬ ìƒì„±
    data_factory = DataLoaderFactory(config_manager)
    
    print("ğŸ—ƒï¸ ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸:")
    
    # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader = data_factory.create_train_val_loaders(
        batch_size=16,
        augmentation_level="medium",
        use_weighted_sampler=True
    )
    
    print(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ:")
    print(f"   í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
    print(f"   ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
    
    # ì²« ë²ˆì§¸ ë°°ì¹˜ í™•ì¸
    train_batch = next(iter(train_loader))
    print(f"   ë°°ì¹˜ í˜•íƒœ: {train_batch['image'].shape}")
    print(f"   íƒ€ê²Ÿ ë¶„í¬: {torch.bincount(train_batch['target'])[:5].tolist()}...")

